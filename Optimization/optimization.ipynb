{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #1: A first very bad idea solution: Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'batch_size': 32, 'num_hidden_units': 256, 'dropout_rate': 0.5}\n",
      "Best score: 0.978147424396756\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    'learning_rate': np.linspace(0.01, 0.1, 10),\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'num_hidden_units': [32, 64, 128, 256],\n",
    "    'dropout_rate': np.linspace(0.0, 0.5, 6)\n",
    "}\n",
    "\n",
    "num_iterations = 100\n",
    "\n",
    "def evaluate_model(params):\n",
    "    # Here, we can train and test a model or perform any other evaluation task\n",
    "    score = np.random.random()  # Random score for demonstration purposes\n",
    "    return score\n",
    "\n",
    "# Perform random search\n",
    "best_params = None\n",
    "best_score = float('-inf') ## Python assigns the highest possible float value\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Sample random hyperparameters\n",
    "    params = {param: np.random.choice(values) for param, values in search_space.items()}\n",
    "\n",
    "    # Evaluate the performance using the current hyperparameters\n",
    "    score = evaluate_model(params)\n",
    "\n",
    "    # Update the best hyperparameters if the score is improved\n",
    "    if score > best_score:\n",
    "        best_params = params\n",
    "        best_score = score\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #2: Random Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Solution: -0.10330336119456618\n",
      "Best Value: 3.989328415565905\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "'''\n",
    "1.Initialize the best solution and its value.\n",
    "2. Generate a random neighbor\n",
    "3. Update the best solution if the neighbor is better\n",
    "'''\n",
    "def objective_function(x):\n",
    "    return -(x**2) + 4\n",
    "\n",
    "def random_neighbor(solution, search_range):\n",
    "    # Generate a random neighbor within the search range\n",
    "    neighbor = solution + random.uniform(-search_range, search_range)\n",
    "    return neighbor\n",
    "\n",
    "def random_local_search(search_range, max_iterations):\n",
    "    # step-1\n",
    "    best_solution = random.uniform(-search_range, search_range)\n",
    "    best_value = objective_function(best_solution)\n",
    "\n",
    "    # Perform random local search\n",
    "    iterations = 0\n",
    "    while iterations < max_iterations:\n",
    "        # step-2\n",
    "        neighbor = random_neighbor(best_solution, search_range)\n",
    "        neighbor_value = objective_function(neighbor)\n",
    "\n",
    "        # step-3\n",
    "        if neighbor_value > best_value:\n",
    "            best_solution = neighbor\n",
    "            best_value = neighbor_value\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return best_solution, best_value\n",
    "\n",
    "# Set the search range and maximum number of iterations\n",
    "search_range = 10\n",
    "max_iterations = 100\n",
    "\n",
    "# Run the random local search algorithm\n",
    "best_solution, best_value = random_local_search(search_range, max_iterations)\n",
    "\n",
    "# Print the result\n",
    "print(\"Best Solution:\", best_solution)\n",
    "print(\"Best Value:\", best_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Order Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Order Optimization\n",
    "Second-order optimization methods, such as Newton's method and variants like the Gauss-Newton method or the Levenberg-Marquardt algorithm, use the second-order derivatives of the loss function with respect to the model parameters to update the parameters. These methods provide more information about the curvature of the loss function compared to first-order methods, which only use the gradient information.\n",
    "\n",
    "    The Newton's method requires the inversion of the Hessian matrix, which can be computationally expensive and may not always be feasible for large-scale problems. \n",
    "\n",
    "1. Newton's method or Newton-Raphson method:\n",
    "`θ_new = θ_old - H^(-1) * ∇L(θ_old)`\n",
    "2.  the Gauss-Newton method:\n",
    "3. Levenberg-Marquardt algorithm:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In practice,** it is currently not common to see L-BFGS or similar second-order methods applied to large-scale Deep Learning and Convolutional Neural Networks. Instead, SGD variants based on (Nesterov’s) momentum are more standard because they are simpler and scale more easily."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

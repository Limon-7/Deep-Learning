{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of content\n",
    "<a id='h_cell'></a>\n",
    "\n",
    "|#|Topic|Code|\n",
    "|--:|:---:|---:|\n",
    "|01| [Supervised Learning](#sl_cell)||\n",
    "|02| [UnSupervised Learning](#usl_cell)||\n",
    "|04| [Semi-Supervised Learning](#ssl_cell)||\n",
    "|04| [Reinforcement Learning](#rl_cell)||\n",
    "|05| [Data](#data_cell)||\n",
    "|06| [Parameter and Hyperparameter](#p_hp_cell)||\n",
    "|07| [Bais, Variance, Overfittig and Underfitting](#b_v__cell)||\n",
    "|08| [Evaluation Matrix](#em_cell)||\n",
    "|09| [PCA](#pca_cell)||\n",
    "|10| [Kross Validation](#cv_cell)||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI vs ML vs DL\n",
    "\n",
    "<p align=\"center\"><img width=\"80%\" src=\"../images/AI_ML_DL.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***AI:*** Artificial Intelligence is a technique that allows machines to act like humans by replicating their behavior and nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ***ML:*** Machine Learning is a subset of artificial intelligence. It allows the machines to learn and make predictions based on its experience(data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ***Deep Leraning:*** Deep learning is a subfield of machine learning that focuses on training artificial neural networks to perform tasks by learning from data. It is inspired by the structure and function of the human brain, where interconnected neurons process information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation:\n",
    "1. Trainin Set: $D={\\displaystyle\\{\\langle {\\textbf{\\color{green}X}_{j}^{[i]}\\;,\\;y^{[i]} }\\rangle}\\;,\\;i= 1,\\ldots ,n\\}\\text{ where i is the number of samples and j is the number of features.}$\n",
    "2. Unknown function: $f(\\textbf{\\color{green}X})=y$\n",
    "3. Hypothesis: $h(\\textbf{\\color{green}X})=\\hat y \\text{\\color{red} ; sometimes t or o}$\n",
    "    * Classification: $h: \\mathbb R^m \\rightarrow y\\;;\\; \\mathbb R^m \\text{ is the m dimentional feature vector and } \\mathcal {y} \\text{ is the target and } y={\\{1,\\cdots , k\\}}\\;; y\\geq 2 $\n",
    "    * Regression: $h: \\mathbb R^m \\rightarrow \\mathbb R\\text{ a scalar value}$\n",
    "4. Representation: \n",
    "    * Feature vector(column vector(n x 1) ): $\\textbf{\\color{green} X}=\\begin{bmatrix} X_1\\\\ X_2\\\\\\vdots\\\\ X_m\\end{bmatrix}$\n",
    "    \n",
    "    * Design Matrix: $\\textbf{\\color{green} X}=\\displaystyle \\begin{bmatrix} X_{1}^{T}\\\\ X_{2}^{T}\\\\\\vdots\\\\ X_{m}^{T}\\end{bmatrix}=\\begin{bmatrix} X_{1}^{[1]} & X_{2}^{[1]}& \\cdots & X_{m}^{[1]}\\\\ X_{1}^{[2]} & X_{2}^{[2]}& \\cdots & X_{m}^{[2]}\\\\\\vdots & \\vdots &\\cdots &\\vdots\\\\ X_{1}^{[n]} & X_{2}^{[n]}& \\cdots & X_{m}^{[n]}\\end{bmatrix}$\n",
    "    \n",
    "    * Unstrature data:\n",
    "        * pytorch: NCHW=> [64,3,28,28]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1. Supervised Learning:](#h_cell)\n",
    "\n",
    "<a id='sl_cell'></a>\n",
    "\n",
    "In supervised learning, the model learns from labeled training data, where each example consists of input features and their corresponding output labels. The goal is to learn a mapping between the input and output variables, allowing the model to make predictions or classify new, unseen data.\n",
    "\n",
    "The two types of supervised learning approaches are-\n",
    "1. Classification\n",
    "2. Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Classification:\n",
    "Classification is a supervised learning task where the goal is to predict a categorical or discrete class label for a given input.\n",
    "\n",
    "Some common types of classification-\n",
    "\n",
    "1. Binary Classification: In binary classification, the target variable has only two possible classes. The task is to assign an input to one of the two classes.\n",
    "    - Examples: spam detection (spam vs. non-spam emails), disease diagnosis (disease present vs. not present), and sentiment analysis (positive vs. negative sentiment).\n",
    "    - Algorithm: Logistic Regression, k-Nearest Neighbors, Decision Trees, Support Vector Machine, Naive Bayes.\n",
    "    \n",
    "2. Multi-class Classification:  In multi-class classification, the target variable has more than two classes. The task is to assign an input to one of multiple classes. Examples: image classification (identifying objects from a set of classes), document categorization (assigning articles to different topics), hand gesture recognition (recognizing various hand gestures).\n",
    "    - Algorithm: k-Nearest Neighbors, Decision Trees, Naive Bayes, Random Forest, Gradient Boosting.\n",
    "\n",
    "3. Multi-label Classification: In multi-label classification,  one or more class labels may be predicted for each input. It is common to model multi-label classification tasks with a model that predicts multiple outputs, with each output taking predicted as a Bernoulli probability distribution. \n",
    "    - Example: image tagging, document classification with multiple topics.\n",
    "    - Algorithm: Multi-label Decision Trees, Multi-label Random Forests, Multi-label Gradient Boosting.\n",
    "\n",
    "4. Imbalanced Classification: Imbalanced classification refers to classification tasks where the number of examples in each class is unequally distributed.\n",
    "    - Example: Fraud detection, Outlier detection, Medical diagnostic tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Regression:\n",
    "Regression analysis is a statistical technique used to model the relationship between a dependent variable (response) and one or more independent variables (predictors). It aims to estimate the parameters of the regression equation and make predictions or inferences about the dependent variable based on the independent variables.\n",
    "\n",
    "It is mainly used for prediction, forecasting, time series modeling, and determining the causal-effect relationship between variables.\n",
    "\n",
    "There are different types of regression techniques available-\n",
    "1. Linear Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "2. Logistic Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "3. Polynomial Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "4. Support Vector Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "5. Decision Tree Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "6. Random Forest Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "7. Ridge Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n",
    "8. Lasso Regression:\n",
    "    - Example:\n",
    "    - Algorithm:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Challenge of Supervised Learning:\n",
    "Although supervised learning can offer businesses advantages, such as deep data insights and improved automation, there are some challenges when building sustainable supervised learning models. The following are some of these challenges:\n",
    "\n",
    "1. Supervised learning models can require certain levels of expertise to structure accurately.\n",
    "2. Training supervised learning models can be very time intensive.\n",
    "3. Datasets can have a higher likelihood of human error, resulting in algorithms learning incorrectly.\n",
    "4. Unlike unsupervised learning models, supervised learning cannot cluster or classify data on its own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2. UnSupervised Learning](#h_cell)\n",
    "<a id='usl_cell'></a>\n",
    "\n",
    "Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets. These algorithms discover hidden patterns or data groupings without the need for human intervention. Its ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation, and image recognition.\n",
    "\n",
    "Data: x =>Just Data, no labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Unsupervised learning models*** are utilized for three main tasks—clustering, association, and dimensionality reduction.\n",
    "\n",
    "1. Clustering: Clustering is a data mining technique which groups unlabeled data based on their similarities or differences. Clustering algorithms are used to process raw, unclassified data objects into groups represented by structures or patterns in the information. Clustering algorithms can be categorized into a few types, specifically exclusive, overlapping, hierarchical, and probabilistic.\n",
    "\n",
    "2. An association rule: An association rule is a rule-based method for finding relationships between variables in a given dataset. These methods are frequently used for market basket analysis, allowing companies to better understand relationships between different products. Understanding consumption habits of customers enables businesses to develop better cross-selling strategies and recommendation engines. Examples of this can be seen in Amazon’s “Customers Who Bought This Item Also Bought” or Spotify’s \"Discover Weekly\" playlist. While there are a few different algorithms used to generate association rules, such as Apriori, Eclat, and FP-Growth, the Apriori algorithm is most widely used.\n",
    "\n",
    "3. Dimensionality reduction: While more data generally yields more accurate results, it can also impact the performance of machine learning algorithms (e.g. overfitting) and it can also make it difficult to visualize datasets. Dimensionality reduction is a technique used when the number of features, or dimensions, in a given dataset is too high. It reduces the number of data inputs to a manageable size while also preserving the integrity of the dataset as much as possible. It is commonly used in the preprocessing data stage, and there are a few different dimensionality reduction methods that can be used, such as:\n",
    "    \n",
    "    * Principal component analysis: Principal component analysis (PCA) is a type of dimensionality reduction algorithm which is used to reduce redundancies and to compress datasets through feature extraction. This method uses a linear transformation to create a new data representation, yielding a set of \"principal components.\" The first principal component is the direction which maximizes the variance of the dataset. While the second principal component also finds the maximum variance in the data, it is completely uncorrelated to the first principal component, yielding a direction that is perpendicular, or orthogonal, to the first component. This process repeats based on the number of dimensions, where a next principal component is the direction orthogonal to the prior components with the most variance.\n",
    "    \n",
    "    * Singular value decomposition: Singular value decomposition (SVD) is another dimensionality reduction approach which factorizes a matrix, A, into three, low-rank matrices. SVD is denoted by the formula, A = USVT, where U and V are orthogonal matrices. S is a diagonal matrix, and S values are considered singular values of matrix A. Similar to PCA, it is commonly used to reduce noise and compress data, such as image files.\n",
    "    \n",
    "    * Autoencoders: Autoencoders leverage neural networks to compress data and then recreate a new representation of the original data’s input. Looking at the image below, you can see that the hidden layer specifically acts as a bottleneck to compress the input layer prior to reconstructing within the output layer. The stage from the input layer to the hidden layer is referred to as “encoding” while the stage from the hidden layer to the output layer is known as “decoding.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised learning Example:\n",
    "Unsupervised learning provides an exploratory path to view data, allowing businesses to identify patterns in large volumes of data more quickly when compared to manual observation. Some of the most common real-world applications of unsupervised learning are:\n",
    "\n",
    "1. News Sections: Google News uses unsupervised learning to categorize articles on the same story from various online news outlets. For example, the results of a presidential election could be categorized under their label for “US” news.\n",
    "\n",
    "2. Computer vision: Unsupervised learning algorithms are used for visual perception tasks, such as object recognition.\n",
    "Medical imaging: Unsupervised machine learning provides essential features to medical imaging devices, such as image detection, classification and segmentation, used in radiology and pathology to diagnose patients quickly and accurately.\n",
    "\n",
    "3. Anomaly detection: Unsupervised learning models can comb through large amounts of data and discover atypical data points within a dataset. These anomalies can raise awareness around faulty equipment, human error, or breaches in security.\n",
    "\n",
    "4. Customer personas: Defining customer personas makes it easier to understand common traits and business clients' purchasing habits. Unsupervised learning allows businesses to build better buyer persona profiles, enabling organizations to align their product messaging more appropriately.\n",
    "\n",
    "5. Recommendation Engines: Using past purchase behavior data, unsupervised learning can help to discover data trends that can be used to develop more effective cross-selling strategies. This is used to make relevant add-on recommendations to customers during the checkout process for online retailers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge of Unsupervised Learning:\n",
    "While unsupervised learning has many benefits, some challenges can occur when it allows machine learning models to execute without any human intervention. Some of these challenges can include:\n",
    "1. Computational complexity due to a high volume of training data\n",
    "2. Longer training times\n",
    "3. Higher risk of inaccurate results\n",
    "4. Human intervention to validate output variables\n",
    "5. Lack of transparency into the basis on which data was clustered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Supervised vs Unsupervised Learning:](#h_cell)\n",
    "<a id='s_us_cell'></a>\n",
    "\n",
    "|                | Supervised Learning                      | Unsupervised Learning                    |\n",
    "| -------------- | ---------------------------------------- | ---------------------------------------- |\n",
    "| Data structure | Data: (x, y), and x is data, y is label  | Data: x, Just data, no labels!           |\n",
    "| Data price     | Training data is expensive in a lot of cases. | Training data are cheap!                 |\n",
    "| Goal           | Learn a function to map x -> y           | Learn some underlying hidden structure of the data |\n",
    "| Examples       | Classification, regression, object detection, semantic segmentation, image captioning | Clustering, dimensionality reduction, feature learning, density estimation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3. Semi-Supervised Learning](#h_cell)\n",
    "<a id='ssl_cell'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. Reinforcement Learning](#h_cell)\n",
    "<a id='rl_cell'></a>\n",
    "\n",
    "Reinforcement Learning(RL) is a type of machine learning technique that enables an agent to learn in an interactive environment by trial and error using feedback from its own actions and experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does reinforcement learning work?\n",
    "1. Agent: It is an assumed entity which performs actions in an environment to gain some reward.\n",
    "2. Environment (e): A scenario that an agent has to face.\n",
    "3. Reward (R): An immediate return given to an agent when he or she performs specific action or task.\n",
    "4. State (s): State refers to the current situation returned by the environment.\n",
    "5. Policy (π): It is a strategy which is applied by the agent to decide the next action based on the current state.\n",
    "6. Value (V): It is expected long-term return with discount, as compared to the short-term reward.\n",
    "7. Value Function: It specifies the value of a state that is the total amount of reward. It is an agent which should be expected beginning from that state.\n",
    "8. Model of the environment: This mimics the behavior of the environment. It helps you to make inferences to be made and also determine how the environment will behave.\n",
    "9. Model based methods: It is a method for solving reinforcement learning problems which use model-based methods.\n",
    "10. Q value or action value (Q): Q value is quite similar to value. The only difference between the two is that it takes an additional parameter as a current action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. Data:](#h_cell)\n",
    "<a id='data_cell'></a>\n",
    "\n",
    "There are several types of data within the world of big data. Here’s a guide to structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure Data:\n",
    "Structured data is typically quantitative data that is organized and easily searchable. The programming language Structured Query Language (SQL) is used in a relational database to “query” to input and search within structured data. Examples of structured data include names, addresses, credit card numbers, telephone numbers, star ratings from customers, bank information, and other data that can be easily searched using SQL. Data format could be CSV or XML.\n",
    "Structured data is often referred to as quantitative data. It means that such data commonly contains precise numbers or textual elements that can be counted. The analysis methods are clear and easy-to-apply. Among them there are:\n",
    "\n",
    "1. classification or arranging stored items of data into similar classes based on common features,\n",
    "2. regression or investigation of the relationships and dependencies between variables, and\n",
    "3. data clustering or organizing the data points into specific groups based on various attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unstructured Data:\n",
    "Unstructured data is every other type of data that is not structured. Approximately 80-90% of data is unstructured, meaning it has huge potential for competitive advantage if companies find ways to leverage it [1]. Unstructured data includes content such as emails, images, videos, audio files, social media posts, PDFs, and much more. Data format like pdf, mp3, \n",
    "\n",
    "Unstructured data is typically stored in data lakes, NoSQL databases, data warehouses, and applications. Today, this information can be processed by artificial intelligence algorithms and delivers huge value for organizations.\n",
    "1. Chatbots: Chatbots are programmed to perform text analysis to answer customer questions and provide the right information.\n",
    "\n",
    "2. Market predictions: Data can be maneuvered to predict changes in the stock market, so analysts can adjust their calculations and investment decisions.\n",
    "\n",
    "Unstructured data, in turn, is often classified as qualitative data containing subjective information that can’t be handled using traditional methods and software analytics tools. For instance, qualitative data can flow from customer surveys or social media feedback in a text form. To process and analyze qualitative data, more cutting-edge analytics techniques are required such as:\n",
    "- data stacking or investigation of large volumes of data, splitting them into smaller items and stacking the variables - with similar values into a single group, and\n",
    "- data mining or the process of detecting certain patterns, oddities, and interactions in large data sets to express possible outcomes in advance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi Structured:\n",
    "Semi-structured data is a mix of both types of data. A photo taken on your iPhone is unstructured, but it might be accompanied by a timestamp and a geotagged location. Some phones will tag photos based on faces or objects, adding another element of structured data. With these classifiers, this photo is considered semi-structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [6. Parameter and Hyperparameter](#h_cell)\n",
    "<a id='p_hp_cell'></a>\n",
    "\n",
    "***Parameter:*** Parameters are the internal variables that a model learns from training data in order to make predictions or fit the data. These parameters directly affect the behavior and outcome of the model.<br>\n",
    "`Parameters → Learned from data.`\n",
    "\n",
    "***Hyperparameter***: Hyperparameters, on the other hand, are external configuration settings that are not learned by the model during training, but are set by the user before training begins.<br>\n",
    "`Hyperparameters → Set before training and influence the learning process.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [7. Bias, Variance, Underfitting, overfitting:](#h_cell)\n",
    "<a id='b_v__cell'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Bias:\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. Resulted Error from Training Data.\n",
    "* High Bias: if the average prediction values are far away from actual values.\n",
    "* Low Bias: Distance between prediction and actual values are minimal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: -1.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Actual target values\n",
    "actual_values = np.array([10, 15, 12, 8, 20])\n",
    "\n",
    "# Predicted values from a model\n",
    "predicted_values = np.array([8, 14, 11, 7, 18])\n",
    "\n",
    "# Calculate the bias\n",
    "bias = np.mean(predicted_values - actual_values)\n",
    "\n",
    "print(\"Bias:\", -7/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXXElEQVR4nO3deVxU5f4H8M8BZIdxhYFEQTQV9yXNPVMDLW5ebbH0htrPjDTDLdvMvJVEZotWmnbTuubVyi0tKXHXUEzEQlwJd3B3QAjUmfP7g2ZimDMwwDDnnJnP+/XideOZMzOP01zPp+f5Ps8jiKIogoiIiEiF3OTuABEREVF1McgQERGRajHIEBERkWoxyBAREZFqMcgQERGRajHIEBERkWoxyBAREZFqMcgQERGRajHIEBERkWoxyBBV4tSpUxAEAcuWLZO7K1QDo0ePRnh4uNzdsNkbb7wBQRCqdO2VK1dquVfA9u3bIQgCtm/fXuvvRWQLBhlyacuWLYMgCPj111/l7kqtMd7kjD916tRBeHg4Jk2ahBs3bsjdPaqCOXPmYN26dXZ/3dGjR5t9Rzw8PBAWFoYRI0YgKyvL7u9HZE8ecneASOmaNm2KP//8E3Xq1JG7KzWycOFC+Pv7o7CwEFu2bMGCBQuQnp6O3bt3y901h1iyZAkMBoPc3bDZa6+9hpdeesmsbc6cOXjkkUcwdOhQu7+fl5cXPv/8cwDAnTt3kJ2djUWLFiE5ORlZWVkIDQ0FAPTt2xd//vknPD097d4HoupgkCGqhCAI8Pb2lrsbFSoqKoKvr2+F1zzyyCNo2LAhAGD8+PEYMWIEVq1ahbS0NHTr1s0R3QQAGAwG3Lp1y+GfqdqCqIeHBzw8HPdXtIeHB0aNGmXWdu+99+Khhx7CDz/8gHHjxgEA3NzcFP//B3ItnFoiqoRUjczo0aPh7++P8+fPY+jQofD390ejRo0wbdo06PV6s+cbDAZ8+OGHaNOmDby9vREcHIzx48fj+vXrZtetX78eDz74IEJDQ+Hl5YXIyEi8+eabFq933333oW3btjhw4AD69u0LX19fvPLKK1X+c/Xp0wcAkJ2dbda+b98+xMTEQKPRwNfXF/369cOePXssnr99+3Z07doV3t7eiIyMxGeffSZZ1yEIAiZOnIivv/4abdq0gZeXF5KTkwEA58+fx9ixYxEcHAwvLy+0adMGX3zxhcV7LViwAG3atIGvry/q1auHrl27YsWKFabHCwoKkJCQgPDwcHh5eSEoKAiDBg1Cenq66RqpGpnCwkJMnToVYWFh8PLyQsuWLfHee+9BFEXJP8O6devQtm1bU1+Nfw5rRFFEw4YNMWXKFFObwWBA3bp14e7ubja1l5SUBA8PD9y8eROAZY2MIAgoLCzEl19+aZoCGj16tNn73bhxA6NHj0bdunWh0WgwZswYFBUVVdjHimi1WgAwC1RSNTK7du3Co48+iiZNmsDLywthYWGYPHky/vzzT7PXy8vLw5gxY9C4cWN4eXkhJCQEDz/8ME6dOlXtPhJxRIaomvR6PaKjo9G9e3e89957SElJwbx58xAZGYn4+HjTdePHj8eyZcswZswYTJo0CTk5Ofj4449x8OBB7NmzxzRSsGzZMvj7+2PKlCnw9/fH1q1b8frrryM/Px9z5841e++rV69i8ODBGDFiBEaNGoXg4OAq999486hXr56pbevWrRg8eDC6dOmCWbNmwc3NDUuXLsX999+PXbt2mUZuDh48iJiYGISEhGD27NnQ6/X497//jUaNGkm+19atW/HNN99g4sSJaNiwIcLDw3Hx4kXce++9ppDQqFEjbNq0CU8//TTy8/ORkJAAoHRKaNKkSXjkkUfwwgsvoLi4GL/99hv27duHJ598EgDw7LPP4rvvvsPEiRMRFRWFq1evYvfu3Thy5Ag6d+4s2SdRFPGPf/wD27Ztw9NPP42OHTvip59+wvTp03H+/Hl88MEHZtfv3r0ba9aswXPPPYeAgADMnz8fw4cPx5kzZ9CgQQPJ9xAEAb169cLOnTtNbb/99ht0Oh3c3NywZ88ePPjggwBKw0CnTp3g7+8v+Vr//e9/8X//93/o1q0bnnnmGQBAZGSk2TWPPfYYIiIikJiYiPT0dHz++ecICgpCUlKS5GuWZywW1uv1+OOPPzBjxgw0aNAADz30UIXP+/bbb1FUVIT4+Hg0aNAAaWlpWLBgAc6dO4dvv/3WdN3w4cNx+PBhPP/88wgPD8elS5ewefNmnDlzRlWF2KQwIpELW7p0qQhA3L9/v9VrcnJyRADi0qVLTW1xcXEiAPHf//632bWdOnUSu3TpYvp9165dIgDx66+/NrsuOTnZor2oqMjivcePHy/6+vqKxcXFprZ+/fqJAMRFixbZ9GecNWuWCEA8duyYePnyZfHUqVPiF198Ifr4+IiNGjUSCwsLRVEURYPBILZo0UKMjo4WDQaDWb8iIiLEQYMGmdpiY2NFX19f8fz586a2EydOiB4eHmL5v1YAiG5ubuLhw4fN2p9++mkxJCREvHLliln7iBEjRI1GY/o8Hn74YbFNmzYV/hk1Go04YcKECq+Ji4sTmzZtavp93bp1IgDxrbfeMrvukUceEQVBEE+ePGn2Z/D09DRrO3TokAhAXLBgQYXvO3fuXNHd3V3Mz88XRVEU58+fLzZt2lTs1q2bOGPGDFEURVGv14t169YVJ0+ebHqe8d9bWX5+fmJcXJzFexivHTt2rFn7P//5T7FBgwYV9k8U//4+l/+56667xAMHDphdu23bNhGAuG3bNlOb1Hc3MTFRFARBPH36tCiKonj9+nURgDh37txK+0NUFZxaIqqBZ5991uz3Pn364I8//jD9/u2330Kj0WDQoEG4cuWK6adLly7w9/fHtm3bTNf6+PiY/rmgoABXrlxBnz59UFRUhKNHj5q9j5eXF8aMGVOlvrZs2RKNGjVCeHg4xo4di+bNm2PTpk2m2pqMjAycOHECTz75JK5evWrqa2FhIQYMGICdO3fCYDBAr9cjJSUFQ4cONRWAAkDz5s0xePBgyffu168foqKiTL+LoojVq1cjNjYWoiiafTbR0dHQ6XSmaaG6devi3Llz2L9/v9U/W926dbFv3z5cuHDB5s/jxx9/hLu7OyZNmmTWPnXqVIiiiE2bNpm1Dxw40GwEpH379ggMDDT79y2lT58+0Ov1+OWXXwCUjrz06dMHffr0wa5duwAAmZmZuHHjhmm6r7qkvo9Xr15Ffn5+pc/19vbG5s2bsXnzZvz000/47LPP4O/vjyFDhuD48eMVPrfsd7ewsBBXrlxBz549IYoiDh48aLrG09MT27dvt5hWJaoJTi0RVZO3t7fFVEq9evXM/pI+ceIEdDodgoKCJF/j0qVLpn8+fPgwXnvtNWzdutXixqPT6cx+v+uuu6q8amT16tUIDAzE5cuXMX/+fOTk5JjdgE6cOAEAiIuLs/oaOp0OxcXF+PPPP9G8eXOLx6XaACAiIsLs98uXL+PGjRtYvHgxFi9eLPkc42czY8YMpKSkoFu3bmjevDkeeOABPPnkk+jVq5fp2nfffRdxcXEICwtDly5dMGTIEDz11FNo1qyZ1T/L6dOnERoaioCAALP21q1bmx4vq0mTJhavUf7ft5TOnTvD19cXu3btQnR0NHbt2oXZs2dDq9ViwYIFKC4uNgWa3r17V/halSnfR+O04fXr1xEYGFjhc93d3TFw4ECztiFDhqBFixZ4+eWXsXr1aqvPPXPmDF5//XV8//33Fp+H8bvr5eWFpKQkTJ06FcHBwaZC4qeeespUi0NUHQwyRNXk7u5e6TUGgwFBQUH4+uuvJR83BqEbN26gX79+CAwMxL///W9ERkbC29sb6enpmDFjhsWy4bIBxFZ9+/Y1rVqKjY1Fu3btMHLkSBw4cABubm6m95g7dy46duwo+Rr+/v4oLi6u8nuX76/xvUaNGmU1OLVv3x5AabA4duwYNm7ciOTkZKxevRqffvopXn/9dcyePRtAaW1Inz59sHbtWvz888+YO3cukpKSsGbNGqujRFVl7d+3WK4wuLw6deqge/fu2LlzJ06ePIm8vDz06dMHwcHBuH37Nvbt24ddu3ahVatWVmuMaruP1jRu3BgtW7Y0q/EpT6/XY9CgQbh27RpmzJiBVq1awc/PD+fPn8fo0aPNvrsJCQmIjY3FunXr8NNPP2HmzJlITEzE1q1b0alTp2r1kYhBhqgWRUZGIiUlBb169aowfGzfvh1Xr17FmjVr0LdvX1N7Tk5OrfTL398fs2bNwpgxY/DNN99gxIgRpmmTwMBAi/8yLysoKAje3t44efKkxWNSbVIaNWqEgIAA6PX6Ct/LyM/PD48//jgef/xx3Lp1C8OGDcPbb7+Nl19+2bQUOCQkBM899xyee+45XLp0CZ07d8bbb79tNcg0bdoUKSkpKCgoMBuVMU7jNW3a1KY/iy369OmDpKQkpKSkoGHDhmjVqhUEQUCbNm2wa9cu7Nq1q9KCWgA27/RrT3fu3DGtpJLy+++/4/jx4/jyyy/x1FNPmdo3b94seX1kZCSmTp2KqVOn4sSJE+jYsSPmzZuH5cuX273v5BpYI0NUix577DHo9Xq8+eabFo/duXPHtPzW+F/SZf/L+datW/j0009rrW8jR45E48aNTStaunTpgsjISLz33nuSN67Lly+b+jpw4ECsW7fOrCbl5MmTFnUl1ri7u2P48OFYvXo1MjMzrb4XULpCqyxPT09ERUVBFEXcvn0ber3eYuotKCgIoaGhKCkpsdqHIUOGQK/X4+OPPzZr/+CDDyAIgt1GcoDSIFNSUoIPP/wQvXv3NgWSPn364L///S8uXLhgU32Mn5+fQ3djPn78OI4dO4YOHTpYvUbquyuKIj766COz64qKiixG8yIjIxEQEFDhvyeiynBEhgjAF198IbknyAsvvFCj1+3Xrx/Gjx+PxMREZGRk4IEHHkCdOnVw4sQJfPvtt/joo4/wyCOPoGfPnqhXrx7i4uIwadIkCIKA//73v9WeErBFnTp18MILL2D69OlITk5GTEwMPv/8cwwePBht2rTBmDFjcNddd+H8+fPYtm0bAgMDsWHDBgCle5z8/PPP6NWrF+Lj402BoG3btsjIyLDp/d955x1s27YN3bt3x7hx4xAVFYVr164hPT0dKSkpuHbtGgDggQcegFarRa9evRAcHIwjR47g448/xoMPPoiAgADcuHEDjRs3xiOPPIIOHTrA398fKSkp2L9/P+bNm2f1/WNjY9G/f3+8+uqrOHXqFDp06ICff/4Z69evR0JCgsXS5pro0aMHPDw8cOzYMdPSaaB0um/hwoUAYFOQ6dKlC1JSUvD+++8jNDQUERER6N69u136eOfOHdOoiMFgwKlTp7Bo0SIYDAbMmjXL6vNatWqFyMhITJs2DefPn0dgYCBWr15tUStz/PhxDBgwAI899hiioqLg4eGBtWvX4uLFixgxYoRd/gzkomRaLUWkCMbl19Z+zp49a3X5tZ+fn8XrSS2ZFUVRXLx4sdilSxfRx8dHDAgIENu1aye++OKL4oULF0zX7NmzR7z33ntFHx8fMTQ0VHzxxRfFn376yWKpa79+/SpdjizVp8uXL1s8ptPpRI1GI/br18/UdvDgQXHYsGFigwYNRC8vL7Fp06biY489Jm7ZssXsuVu2bBE7deokenp6ipGRkeLnn38uTp06VfT29ja7DoDVpdEXL14UJ0yYIIaFhYl16tQRtVqtOGDAAHHx4sWmaz777DOxb9++pv5ERkaK06dPF3U6nSiKolhSUiJOnz5d7NChgxgQECD6+fmJHTp0ED/99FOz9yq//FoURbGgoECcPHmyGBoaKtapU0ds0aKFOHfuXLPl5xX9GZo2bSq5HFrKPffcIwIQ9+3bZ2o7d+6cCEAMCwuzuF7qu3T06FGxb9++oo+PjwjA9N7W/h0bv985OTkV9k1q+XVgYKA4YMAAMSUlxexaqeXXWVlZ4sCBA0V/f3+xYcOG4rhx40zL043/v7ly5Yo4YcIEsVWrVqKfn5+o0WjE7t27i998800lnxxRxQRRrMX/5CMilzJ06FAcPnzYtAKKiKi2sUaGiKql/PbzJ06cwI8//oj77rtPng4RkUviiAwRVUtISAhGjx6NZs2a4fTp01i4cCFKSkpw8OBBtGjRQu7uEZGLYLEvEVVLTEwM/ve//yEvLw9eXl7o0aMH5syZwxBDRA7FERkiIiJSLdbIEBERkWoxyBAREZFqOX2NjMFgwIULFxAQECDL9t5ERERUdaIooqCgAKGhoXBzsz7u4vRB5sKFCwgLC5O7G0RERFQNZ8+eRePGja0+7vRBxngY3NmzZys9xp6IiIiUIT8/H2FhYWaHukpx+iBjnE4KDAxkkCEiIlKZyspCWOxLREREqsUgQ0RERKrFIENERESq5fQ1MrbS6/W4ffu23N0gF1CnTh24u7vL3Q0iIqfg8kFGFEXk5eXhxo0bcneFXEjdunWh1Wq5txERUQ25fJAxhpigoCD4+vryxkK1ShRFFBUV4dKlSwBKT5AmIqLqc+kgo9frTSGmQYMGcneHXISPjw8A4NKlSwgKCuI0ExFRDbh0sa+xJsbX11fmnpCrMX7nWJdFRFQzLh1kjDidRI7G7xwRkX249NQSERGRM9IbRKTlXMOlgmIEBXijW0R9uLs5539AMcgQERE5keTMXMzekIVcXbGpLUTjjVmxUYhp63wLDDi1pDKCIFT488YbbzisL/fdd5/pfb28vHDXXXchNjYWa9asqfJrvfHGG+jYsaP9O0lE5EKSM3MRvzzdLMQAQJ6uGPHL05GcmStTz2oPg4wd6A0iUrOvYn3GeaRmX4XeINbae+Xm5pp+PvzwQwQGBpq1TZs2zXStKIq4c+dOrfUFAMaNG4fc3FxkZ2dj9erViIqKwogRI/DMM8/U6vsSEZE5vUHE7A1ZkLoDGdtmb8iq1XuUHBhkaig5Mxe9k7biiSV78cLKDDyxZC96J22ttdSr1WpNPxqNBoIgmH4/evQoAgICsGnTJnTp0gVeXl7YvXs3Ro8ejaFDh5q9TkJCAu677z7T7waDAYmJiYiIiICPjw86dOiA7777rtL++Pr6QqvVonHjxrj33nuRlJSEzz77DEuWLEFKSorpuhkzZuDuu++Gr68vmjVrhpkzZ5pW7CxbtgyzZ8/GoUOHTCM8y5YtAwC8//77aNeuHfz8/BAWFobnnnsON2/erPHnSETkbNJyrlmMxJQlAsjVFSMt55rjOuUADDI1oNQhvJdeegnvvPMOjhw5gvbt29v0nMTERHz11VdYtGgRDh8+jMmTJ2PUqFHYsWNHld8/Li4O9erVM5tiCggIwLJly5CVlYWPPvoIS5YswQcffAAAePzxxzF16lS0adPGNLL0+OOPAwDc3Nwwf/58HD58GF9++SW2bt2KF198scp9IiJydpcKrIeY6lynFiz2rabKhvAElA7hDYrSOrxS/N///jcGDRpk8/UlJSWYM2cOUlJS0KNHDwBAs2bNsHv3bnz22Wfo169fld7fzc0Nd999N06dOmVqe+2110z/HB4ejmnTpmHlypV48cUX4ePjA39/f3h4eECr1Zq9VkJCgtnz3nrrLTz77LP49NNPq9QnIiJnFxTgXaXrnGVlk6xBJjExEWvWrMHRo0fh4+ODnj17IikpCS1btjRdU1xcjKlTp2LlypUoKSlBdHQ0Pv30UwQHB8vY86oN4fWIdOyuwV27dq3S9SdPnkRRUZFF+Ll16xY6depUrT6Iomi2V8qqVaswf/58ZGdn4+bNm7hz5w4CAwMrfZ2UlBQkJibi6NGjyM/Px507d1BcXIyioiJuZEhEVEa3iPoI0XgjT1cs+R/ZAgCtpjSwONPKJlmnlnbs2IEJEyZg79692Lx5M27fvo0HHngAhYWFpmsmT56MDRs24Ntvv8WOHTtw4cIFDBs2TMZel1LyEJ6fn5/Z725ubhBF86912R1ljTUnP/zwAzIyMkw/WVlZNtXJlKfX63HixAlEREQAAFJTUzFy5EgMGTIEGzduxMGDB/Hqq6/i1q1bFb7OqVOn8NBDD6F9+/ZYvXo1Dhw4gE8++QQAKn0uEZGrcXcTMCs2CkBpaCnL+Pus2ChszspTZFlEdck6IpOcnGz2+7JlyxAUFIQDBw6gb9++0Ol0+M9//oMVK1bg/vvvBwAsXboUrVu3xt69e3HvvffK0W0AVR/Ck1OjRo2QmZlp1paRkYE6deoAAKKiouDl5YUzZ85UeRpJypdffonr169j+PDhAIBffvkFTZs2xauvvmq65vTp02bP8fT0hF6vN2s7cOAADAYD5s2bBze30sz9zTff1Lh/RETOKqZtCBaO6mwx2qL9a7RlUJQWvZO2KrIsoroUVSOj0+kAAPXr1wdQeiO7ffs2Bg4caLqmVatWaNKkCVJTUyWDTElJCUpKSky/5+fn10pfqzKEJ7f7778fc+fOxVdffYUePXpg+fLlyMzMNE0bBQQEYNq0aZg8eTIMBgN69+4NnU6HPXv2IDAwEHFxcVZfu6ioCHl5ebhz5w7OnTuHtWvX4oMPPkB8fDz69+8PAGjRogXOnDmDlStX4p577sEPP/yAtWvXmr1OeHg4cnJykJGRgcaNGyMgIADNmzfH7du3sWDBAsTGxmLPnj1YtGhR7X1QREROIKZtCAZFaSXrX1Kzr9q3LCI9HfjjD2DoUMBDnkihmFVLBoMBCQkJ6NWrF9q2bQsAyMvLg6enJ+rWrWt2bXBwMPLy8iRfJzExERqNxvQTFhZWK/21dQhPCYk2OjoaM2fOxIsvvoh77rkHBQUFeOqpp8yuefPNNzFz5kwkJiaidevWiImJwQ8//GCaHrJmyZIlCAkJQWRkJIYNG4asrCysWrXKrBj3H//4ByZPnoyJEyeiY8eO+OWXXzBz5kyz1xk+fDhiYmLQv39/NGrUCP/73//QoUMHvP/++0hKSkLbtm3x9ddfIzEx0X4fDBGRk3J3E9AjsgEe7ngXekQ2MN2L7FYWodcDbdoAXboAjz4K/PhjTbtcbYJYvnhCJvHx8di0aRN2796Nxo0bAwBWrFiBMWPGmI2wAEC3bt3Qv39/JCUlWbyO1IhMWFgYdDqdRXFpcXExcnJyEBERAW/v6k0BOVPBFDmOPb57RERVlZp9FU8s2Vvpdf8bd6/1EZlt24C/yj1MCgoAf3879PBv+fn50Gg0kvfvshQxtTRx4kRs3LgRO3fuNIUYoHTzt1u3buHGjRtmozIXL160WKZr5OXlBS8vr9rusklFQ3hERERKUqOyCL0e6NwZ+O23v9vuvhs4fFi2aSVA5qklURQxceJErF27Flu3brWYxujSpQvq1KmDLVu2mNqOHTuGM2fOmPY7UQJrQ3hERERKUu2yiB07SsNK2RDz00/AsWOyhhhA5hGZCRMmYMWKFVi/fj0CAgJMdS8ajQY+Pj7QaDR4+umnMWXKFNSvXx+BgYF4/vnn0aNHD1lXLBEREalVZSubzMoi7twB/lrhatK8OXDkiOwBxkjWXixcuBAAzM78AUqXWI8ePRoA8MEHH8DNzQ3Dhw832xCPiIiIqsemsoi33wbK7MoOANi0CYiJcWxnKyFrkLGlztjb2xuffPKJaSM0IiIiqjljWYQFvV56tOXWLcvRGQVQzPJrIiIikllSkmWImTgREEVFhhhAIauWiIjIOTjLQYQux9ooTGEhoPBz7RhkiIjILrivlkrNmwdMm2be9swzwGefydOfKmKQISKiGkvOzEX88nSLvUmMBxEuHNWZYUZppFYkAaoYhSmLNTIkafv27RAEATdu3LD5OeHh4fjwww8d+v72fM+yTp06BUEQkJGRYffXJnI2eoOI2RuyrB5ECJQeRKg3KGIjeQKAZs0sQ8zTT5fWwqgoxAAMMqo0evRoCIKAZ5991uKxCRMmQBAE0/J1terZsydyc3Oh0WgAlJ6MXv7Mreoyfn7GnwYNGiAmJga/ldnoKSwsDLm5uaZzv4jIurScazYfREgy0+sBQQBycszb8/OBzz+v2ksZRKRmX8X6jPNIzb4qW1BlkFGpsLAwrFy5En/++aeprbi4GCtWrECTJk1k7Jl9eHp6QqvVQhBqp0gwJiYGubm5yM3NxZYtW+Dh4YGHHnrI9Li7uzu0Wi08FLLhE5GS2e0gQqpdrVtLF/SKIhAQUKWXSs7MRe+krXhiyV68sDIDTyzZi95JW5GcmWunztqOQUalOnfujLCwMKxZs8bUtmbNGjRp0gSdOnUyu7akpASTJk1CUFAQvL290bt3b+zfv9/smh9//BF33303fHx80L9/f5w6dcriPXfv3o0+ffrAx8cHYWFhmDRpEgoLC23qb2ZmJtzc3HD58mUAwLVr1+Dm5oYRI0aYrnnrrbfQu3dvAOZTS9u3b8eYMWOg0+lMoyhvvPGG6XlFRUUYO3YsAgIC0KRJEyxevLjS/nh5eUGr1UKr1aJjx4546aWXcPbsWVP/yk8t6fV6PP3004iIiICPjw9atmyJjz76yOw1t2/fjm7dusHPzw9169ZFr169cPr0aZs+HyI1Cwqw7eBTW68jOzOOwhw9at5+4UJpiKkiYz1U+VE4Yz2Uo8MMg0xZolha5CTHTzW+TGPHjsXSpUtNv3/xxRcYM2aMxXUvvvgiVq9ejS+//BLp6elo3rw5oqOjce1a6TDv2bNnMWzYMMTGxiIjIwP/93//h5deesnsNbKzsxETE4Phw4fjt99+w6pVq7B7925MnDjRpr62adMGDRo0wI4dOwAAu3btMvsdAHbs2GGxyzNQOs304YcfIjAw0DSKMq1Mhf28efPQtWtXHDx4EM899xzi4+Nx7Ngxm/oFADdv3sTy5cvRvHlzNGggfdqrwWBA48aN8e233yIrKwuvv/46XnnlFXzzzTcAgDt37mDo0KHo168ffvvtN6SmpuKZZ56ptRElIiUxHkRo7dsuoHT1kuRBhFS7Ona0PgoTUvXiayXWQzHIlFVUVHoMuRw/RUVV7u6oUaOwe/dunD59GqdPn8aePXswatQos2sKCwuxcOFCzJ07F4MHD0ZUVBSWLFkCHx8f/Oc//wFQelREZGQk5s2bh5YtW2LkyJEWNTaJiYkYOXIkEhIS0KJFC/Ts2RPz58/HV199heLiyoeLBUFA3759sX37dgAwjbKUlJTg6NGjuH37Nn755Rf069fP4rmenp7QaDQQBME0iuJf5rj4IUOG4LnnnkPz5s0xY8YMNGzYENu2bauwPxs3boS/vz/8/f0REBCA77//HqtWrYKbm/T/JerUqYPZs2eja9euiIiIwMiRIzFmzBhTkMnPz4dOp8NDDz2EyMhItG7dGnFxcU4xzUdUmWofREi1x2AoHYU5dMi8/dy5av2Hs5ES66EYZFSsUaNGePDBB7Fs2TIsXboUDz74IBo2bGh2TXZ2Nm7fvo1evXqZ2urUqYNu3brhyJEjAIAjR46ge/fuZs8rf7r4oUOHsGzZMtPN39/fH9HR0TAYDMgpXzRmRb9+/UxBZseOHbj//vtN4Wb//v0W/bRV+/btTf9sDDuXLl2q8Dn9+/dHRkYGMjIykJaWhujoaAwePLjCqaBPPvkEXbp0QaNGjeDv74/FixfjzJkzAID69etj9OjRiI6ORmxsLD766CPk5jp+rphILsaDCLUa8+kjrcabS68dzcMDcHe3bBdF4K67avTSSqyHYiVjWb6+wM2b8r13NYwdO9Y0vVOb51HdvHkT48ePx6RJkywes3XU4b777kNCQgJOnDiBrKws9O7dG0ePHsX27dtx/fp1dO3aFb7V+BzqlFtCKAgCDAZDhc/x8/ND8+bNTb9//vnn0Gg0WLJkCd566y2L61euXIlp06Zh3rx56NGjBwICAjB37lzs27fPdM3SpUsxadIkJCcnY9WqVXjttdewefNmntROLsOmgwip9hgM0gEmJwcID7fLWyixHopBpixBAPz85O5FlcTExODWrVsQBAHR0dEWj0dGRsLT0xN79uxB06ZNAQC3b9/G/v37kZCQAABo3bo1vv/+e7Pn7d271+z3zp07Iysry+zmX1Xt2rVDvXr18NZbb6Fjx47w9/fHfffdh6SkJFy/fl2yPsbI09MTer2+2u9dGUEQ4ObmZrYKrKw9e/agZ8+eeO6550xt2dnZFtd16tQJnTp1wssvv4wePXpgxYoVDDLkUqweREi1KzAQKCiwbK/BNBJgeeREl6b1EKLxRp6uWLJORkDpKJwj66E4taRy7u7uOHLkCLKysuAukcT9/PwQHx+P6dOnIzk5GVlZWRg3bhyKiorw9NNPAwCeffZZnDhxAtOnT8exY8ewYsUKLFu2zOx1ZsyYgV9++QUTJ05ERkYGTpw4gfXr19tc7Av8XSfz9ddfm0JL+/btUVJSgi1btkjWxxiFh4fj5s2b2LJlC65cuYKiatQUlVVSUoK8vDzk5eXhyJEjeP7553Hz5k3ExsZKXt+iRQv8+uuv+Omnn3D8+HHMnDnTbOVXTk4OXn75ZaSmpuL06dP4+eefceLECbRu3bpG/SQiqpAolv5HePkQc/RojUOM1BLrfnO34R8dSqcJlVIPxSDjBAIDAxEYGGj18XfeeQfDhw/Hv/71L3Tu3BknT57ETz/9hHr16gEonRpavXo11q1bhw4dOmDRokWYM2eO2Wu0b98eO3bswPHjx9GnTx906tQJr7/+OkJDQ6vU1379+kGv15uCjJubG/r27QtBECqsj+nZsyeeffZZPP7442jUqBHefffdKr1vecnJyQgJCUFISAi6d++O/fv349tvv7U6KjR+/HgMGzYMjz/+OLp3746rV6+ajc74+vri6NGjGD58OO6++24888wzmDBhAsaPH1+jfhKR66p0w7mgIEBqgYIoAi1b1ui9K1pivXhnDp7pG6GYeihBFGsY2RQuPz8fGo0GOp3O4mZfXFyMnJwcREREwNub+xuQ4/C7R0QVqfAAzjZa6QCTmQm0aVPj99YbRPRO2mp1dZJx+mjH9P44cPp6rdVDVXT/Los1MkRERApS0QGc7Xu2BwquWD7JjmMSti6xPnD6uiLqoTi1REREpBBWN5wTReQkPYTQ8iEmI8OuIQZQ5hLrinBEhoiISCGkRkO2LR6HiOsS+1LVUmWIEpdYV4QjMkRERApRfpTjVNJDFiHmwbgPsf7guVrrg9qOnGCQAeDk9c6kQPzOEZEU4yjHpi8m4lTSQxaPh8/YiMPa5rU6GqK2IydcemrJuCNsUVERfHx8ZO4NuRLjPjjldyUmUrLym6Nx11776xZRXzLAPPyveTgU2tJhG84Zj5wov3JKa1w5paAjJ1w6yLi7u6Nu3bqmc3l8fX15WjHVKlEUUVRUhEuXLqFu3bqSmxgSKVGFy4EVdFNTtXvugfuvv1o0h8/YCMDxoyFqOXLCpfeRAUpvLHl5ebhx44bjO0cuq27dutBqtQzOpArWlgMbv708FNIOJP4ueGb8R/i5bqTpd1cLjtxHxkaCICAkJARBQUG4ffu23N0hF1CnTh2OxJBqWF0OjNL9RAQAszdkYVCUVnH/pa4KffoAu3dbtosiFnIqzyYuH2SM3N3deXMhIirH1s3R0nKuKWJzNKUrW2f0cKfGlhfs2AH07QuAB3DaiquWiIjIKrVtjqZkxkMY9QMGSIcYUTSFGLIdgwwREVmlts3RlMpYZ5T6ykD0Pn3I7LGRj7+F5N8vyNQz9ePUEhERWWXcHC1PVyxZJ+Oo5cBqpjeICHhkKHKOpVk8Fj5jIwQAf8hQZ+Qsy+kZZIiIyCrj5mjxy9MhAGZhRomboymRu7sbepVre+rR2djZrAsAeeqMnGk5PaeWiIioQsbN0bQa8+kjrcabS68rMny45LLq8BkbTSGmLEfVGRmnucoXcefpihG/PB3JmRLnOikYR2SIiKhSatkcTTEkAsyYR2ZhW+Q9Vp/iiDojZ1xOzyBDREQ24XJgGzzxBLBypUVzjzkpyLOyjN2RdUbOuJyeU0tERET2IAiWIWbtWkAUFXMIozMup2eQISIiqom4OMmpJIgiMHQoAOXUGTnjcnpOLREREVWXVIBZtQp47DGLZiXUGTnjcnqOyBAREVXVM89YH4WRCDFGxjqjhzvehR6RDRxeUGtcTg/IP81lLwwyREREVSEIwJIl5m1ff10aYlRAKdNc9sKpJSIiIhuIDw+F8P16iQfUEWDKUsI0l70wyBAREVVGECymYt585EXcMysBMbJ0qOacZTk9p5aIiIisGTHC6u68X0T2VeVOuM6GIzJERC7GWQ4LrHUSASapXxwW3vsoAPXuhOtsGGSIiFyIMx0WWGvi4oCvvrJoDp+x0aJNjTvhOhtOLRERuQhnOyywVgiCRYj5oNeTkiGmLDXthOtsGGSIiFxAZYcFAqVTJHqD+lbg2IWVfWFST17BR72frPTpatoJ19kwyBARuYCqHBbocqT2hXn5ZUAUTTvhWqt+EVA6NaemnXCdDYMMEZELsHXqIy+/GKnZV7E+4zxSs6869wjN889b3513zhwAzrkTrrNhsS8RkQuwderjzY2Hca3wtul3py0ElgowU6cC771n0WzcCbd8kbTWWT8blRFEUYVbElZBfn4+NBoNdDodAgMD5e4OEZEs9AYRvZO2Wj0s0Brj7V6NW9dLmj5dMqzYsjsvl607lq33b04tERG5AFumSKQ4VSGwIFiGmIkTbT5iQO4DH0kagwwRkYuwdlhgfT/PCp+n+kLgV1+1XguzYIHj+0N2xRoZIiIXInVYYJ7uT0z+5lClz1XlXilSAWbcOGDxYsf3hWoFgwwRkYspf1hgavZVm56nqr1SJk4EPvnEst25y0JdEoMMEZGLM+6VYq0QWEDpCh3V7JUiNQrzj38A69c7vi9U61gjQ0Tk4pxmr5RJk6zXwjDEOC0GGSIisloIrNV4q2PptSBYFu727MmpJBfAqSUiIgIgXQis+L1SrOwLo9cb4O4mcO8XF8AgQ0REJuULgRVNYhrpqk8gukxagZCkrfhHhxB8fyjXbDdep92p2IVxZ18iIlKXhATgo48smsNnbKz0qU63U7ETs/X+zREZIiJSD4lRmGIPT7Sausamp4soDTOzN2RhUJSW00xOgMW+RESkfC+/LBliwmdstDnEGKl+p2IywxEZIiIn4bSFrVJLqgGsP3gOWJlR7ZdV5U7FZIFBhojICSRn5mL2hiznKmx94w1g9mzL9r9KO4Ns3JHYGlXtVExWMcgQEalccmYu4penW+zKm6crRvzydHUWtloZhSm7L0xlOxJbfWmobKdiqhBrZIiIVExvEDF7Q5bkjdzYNntDFvQGlSxQTUy0vjtvuUW2Fe1IbI2qdiommzDIEBGpWFrONbPppPJUVdgqCMArr1i2V7BLSEzbEHzyZGfU8/M0aw/ReGN83wiEqHWnYrIZp5aIiFTM1oJVRRe2fvABMGWKZbsN25wlZ+bizR+ycK3wlqmtvl8dzHywNYa0D8WLMa2dswCaTBhkiIhUzNaCVcUWttpQC2ONtdqg64W3MWHFQSx0ExDTNkQ9OxVTtXBqiYhIxYwFr9bGGASUTrMorrD1009troWR4nS1QVRtDDJERCpWUcGrYgtbBQGYMMGyvQon5jhVbRDViKxBZufOnYiNjUVoaCgEQcC6devMHh89ejQEQTD7iYmJkaezREQKFdM2BAtHdYZW6YWtn39eo1GYspyiNojsQtYamcLCQnTo0AFjx47FsGHDJK+JiYnB0qVLTb97eXk5qntERKoR0zYEg6K0yi1srUEtjBTV1waR3cgaZAYPHozBgwdXeI2Xlxe0Wq2DekREpF7uboLyClv/+1/gqacs26sZYIwq2wyPm965DsXXyGzfvh1BQUFo2bIl4uPjcfVqxVtSl5SUID8/3+yHiMhZ6Q0iUrOvYn3GeaRmX1VWcasg1EqIAVRaG0S1QtHLr2NiYjBs2DBEREQgOzsbr7zyCgYPHozU1FS4u7tLPicxMRGzpc7mICJyMoo9X+mbb4DHH7dst0OAKctYG1T+M9Aq4TMghxFE0c7frGoSBAFr167F0KFDrV7zxx9/IDIyEikpKRgwYIDkNSUlJSgpKTH9np+fj7CwMOh0OgQGBtq720REsrC2h4px/EG2Il8718LYwmlP/XZx+fn50Gg0ld6/FT+1VFazZs3QsGFDnDx50uo1Xl5eCAwMNPshInImitxDZcUK6RBjMNRqiAH+rg16uONd6BHZgCHGxSh6aqm8c+fO4erVqwgJ4XAhEbmuquyh4pDiXxlGYYiMZB2RuXnzJjIyMpCRkQEAyMnJQUZGBs6cOYObN29i+vTp2Lt3L06dOoUtW7bg4YcfRvPmzREdHS1nt4mIZKWYPVS++062URgiI1lHZH799Vf079/f9PuUvw4Ni4uLw8KFC/Hbb7/hyy+/xI0bNxAaGooHHngAb775JveSISKXpog9VDgKQwoha5C57777UFGt8U8//eTA3hARqYOse6isWwf885+W7QaD9XBDVItUVexLREQy7qEiCNIhRhQZYkg2DDJERCrk0POV1q+XDip6PaeSSHaqWrVERER/c8j5SqyFIYVjkCEiUrGanK9U4UZyycmA1Fl4d+4AVnZWJ5IDgwwRkQuq8HiDdqHST1LYKAx39CWAQYaIyOVYO94g4rd9iHlloOUTbt8GPJR1u1DsOVPkcMr6ZhIRUa2ydrzBqaSHpJ+gsFEYwHoQy9MVI355unznTJEsuGqJiMiFlD/eoOu5w5IhZm/WBUWGGEWeM0Wy4ogMEZELKXtsgbVRmPAZG/FRicFRXaoSxZ0zRbJjkCEiciFBAd7oeu4wvvt6hsVjLaeuQYmHp+k6JVLMOVOkGAwyREQupEfzhvhOoj18xkYAtXy8gR0o4pwpUhQGGSIiV5CWBnTvbtHcevJ3+NOz9KZfq8cb2Ims50yRIrHYl4jI2QmCZIjpMSfFFGKAWjrewM5qcs6U3iAiNfsq1mecR2r2VRYEOwmOyBARKYzdNnrLyAA6dbJs1+mAwEDsVumGcsZzpsrvI6OtYB8Z7jvjvARRVOD6OjvKz8+HRqOBTqdDYGCg3N0hIqqQ3W64LnBGkq2Bz9q+M8YrlT4K5apsvX9zaomISCGMN9zyy4uNG70lZ+ZW/iKHD0uHmGvXnCrEAH+fM/Vwx7vQI7KB1ekk7jvj3BhkiIgUwC43XEEA2raVeAERqFfPHt1UnarsO0PqxCBDRKQANbrhZmVJj8Jcvux0ozBVxX1nnB+LfYmIFKDaN1wXqIWpCe474/w4IkNEpABVvuEePSodYs6fZ4gpw7jvjLW1WAJKi6m574x6McgQESlAlW64ggC0bm15kSgCoaG12U3Vqcm+M6QODDJERApgyw33nY5+cHeX+Gs7J4ejMBUw7juj1ZiPeqlhA0CqHPeRISKnZ7cN5hzA2j4yqa8MlH6Cc/8Vbldq+h6Q7fdvBhkicmpq3NG17A23ccFVdOnbwfKiY8eAu+92fOeIHIRB5i8MMkSuS/U7unJFErkw7uxLRC5N1Tu6nj8vHWIyMxliiMrhPjJE5JSqssFcj8gGjutYZTgKQ1QlHJEhIqekuh1dL1+WDjFpaQwxRBVgkCEip6SqHV0FAQgKsmjuMScFyT6NZegQkXowyBCRU1LFjq7Xr0uOwjz8r3kIn7GxaqdeE7koBhkickqK39FVEID6liEqfMZGHAptCUAFRclECsAgQ0ROS5E7uubnS47CPPrkOwifsdGivcJTr4mIq5aIyLnFtA3BoCit3Xd0rdYusVZWJEkFmPIUU5RMpDAMMkTk9NzdBLsusa7ybsGFhYC/v2X7zz8jtVlnYMneSt+zob9XTbpM5LQ4tUREVAXG3YLL71FjtTBXEKRDjCgCgwZVWpRsNPWbDBb9EklgkCEislGVdgv+80/pqaQNG8z2hamoKLmsi/klXMFEJIFBhojIRrbuFuzu7gb4+kpcIAIPPWT6VW8QkZp9FSV3DEgYeDeCA63vacMVTETSWCNDRGSjygpu6+hv48R7/7R84LvvgOHDzZqk6mzq+Vb8V7Jij1UgkhGDDBGRjSraBfhU0kPSD0gcL2DtVO7rRXds6gdXMBH9jVNLREQ2kirMdTfopUPM8uWSIaaiOhtbKeJYBSKF4IgMEZGNjIW58cvTIQDIqcIojFFldTYVEVC6mZ+sxyoQKQxHZIiIqiCmbQgWPtFBMsRkvjG30pOqqzstpIhjFYgUiCMyRERVIQiIkWjW6w1oa0PAsHVaqL6fJ64V3jL9rq1owz0iF8YgQ0RkC4MBcHe3bE9KAl58ERKPSDLW2eTpiiXrZIzTRzum98eB09fteqwCkTNikCEiqoyVM5Iqm0aSUr7OpuwrlJ0+8vRw4xJrIhuwRoaIyBpRlA4xb7xRrRBjpMhTuYlUiiMyRERS7DgKI6W2TuUmcjUMMkREZYki4CYxWD1jBvDOO3Z9K3ufyk3kihhkiIiMankUhojsjzUyRESAdIhJSGCIIVI4jsgQkWvjKAyRqnFEhohcl1SIGTeOIYZIRTgiQ0Sup4JRGL1BRFr2Va4kIlIJBhkici1SIWbkSGD5ciRn5mL2hiyzQx1DKjgaQG8QuXyaSGYMMkTkELLf9CuphUnOzEX88nSLYwPydMWIX55usVFdVUMPEdUOBhkiqnWy3/SlQsy//gV89RWA0pA1e0OW5NlHIkqPDpi9IQuDorRwdxOqHHqIqPaw2JeIapXxpl82xAB/3/STM3Nr780FQTrEiKIpxABAWs41i/6ZXQ4gV1eMtJxrlYYeoDT06A0sGCZyBAYZIpXSG0SkZl/F+ozzSM2+qsgbp6w3fakAM2yY5IqkSwXWQ0z566oSeoio9nFqiUiFZJ+qsVFVbvp226q/GvvCBAV4W32s/HVVCT1EVPs4IkOkMrJO1VSRw2/6UiEmOrrSfWG6RdRHiMYb1kqPBZQGxW4R9asUeoio9jHIEKmI2uozbL2Zn7pSWLM3qqgWJjm50qe7uwmYFRtV+lLlX/qv/50VGwV3N6FKoYeIah+DDJGKqK0+o7KbvtEHKSeqP5IkFWB69qzy7rwxbUOwcFRnaDXm4Uur8TZbhVSV0ENEtY81MkQqorb6DONNP355eoXXlV/ebJNaOCMppm0IBkVpK93vxhh6ytcpaRVYp0Tk7BhkiFREjfUZMW1DkDDwbnyQctzqNVUu+pUKMe3bA4cOVb+jf3F3E2zqg62hh4hqF4MMkYoYp2rydMWSdTICSkcFlFafEd7Q16brKh1JUthJ1baGHiKqPayRIVIRtdZn2GUkSSrENG/Ok6qJXByDDJHK2FqUqiQ1WulT0YqkEyfs2U0iUiFOLRGpkNrqM8oW/QqA2bRYhSNJUgEmOBjIy6ulnhKR2gii6Nzjsvn5+dBoNNDpdAgMDJS7O0QuzeYdiRVWC0NEjmfr/ZsjMkTkMDaNJEmFGG9v4M8/HddRIlINWWtkdu7cidjYWISGhkIQBKxbt87scVEU8frrryMkJAQ+Pj4YOHAgTnBOnEjVjCt9Hu54F3pENvg7xFRUC8MQQ0RWVDnIxMXFYefOnXZ588LCQnTo0AGffPKJ5OPvvvsu5s+fj0WLFmHfvn3w8/NDdHQ0iouVsdkXEdkJp5KIqJqqPLWk0+kwcOBANG3aFGPGjEFcXBzuuuuuar354MGDMXjwYMnHRFHEhx9+iNdeew0PP/wwAOCrr75CcHAw1q1bhxEjRlTrPYlIQRhgiKiGqjwis27dOpw/fx7x8fFYtWoVwsPDMXjwYHz33Xe4ffu23TqWk5ODvLw8DBw40NSm0WjQvXt3pKamWn1eSUkJ8vPzzX6ISIEYYojIDqpVI9OoUSNMmTIFhw4dwr59+9C8eXP861//QmhoKCZPnmyXOpa8v5ZXBgcHm7UHBwebHpOSmJgIjUZj+gkLC6txX4jIjiqqhWGIIaIqqlGxb25uLjZv3ozNmzfD3d0dQ4YMwe+//46oqCh88MEH9upjlbz88svQ6XSmn7Nnz8rSDyKSwFEYIrKzKtfI3L59G99//z2WLl2Kn3/+Ge3bt0dCQgKefPJJ0zrvtWvXYuzYsZg8eXK1O6bVagEAFy9eREjI3/tLXLx4ER07drT6PC8vL3h5eVX7fYmolN4g2m/DPS8v4NYty3YGGCKqoSoHmZCQEBgMBjzxxBNIS0uTDBX9+/dH3bp1a9SxiIgIaLVabNmyxfQe+fn52LdvH+Lj42v02kRUMZs3rrMFR2GIqBZVOch88MEHePTRR+Htbf1wt7p16yInJ6fS17p58yZOnjxp+j0nJwcZGRmoX78+mjRpgoSEBLz11lto0aIFIiIiMHPmTISGhmLo0KFV7TaRy6rqyEpyZi7il6dbnK6dpytG/PJ0289zql8fuH7dsp0BhojsSNYjCrZv347+/ftbtMfFxWHZsmUQRRGzZs3C4sWLcePGDfTu3Ruffvop7r77bpvfg0cUkCur6siK3iCid9JWs+vLElB6OOXuGfdXPM3EURgiqiFb7988a4nISVkbWTFGDKmRldTsq3hiyd5KX/t/4+5Fj8gGlg80aQJIFdg7918zRFQLbL1/y3pEARHVDr1BxOwNWRYhBvj75OnZG7KgN5hfcanAtl2zJa8TBIYYInI4BhkiJ5SWc83q9BBQGmZydcVIy7lm1h4UYL32zep1/fqpal8YvUFEavZVrM84j9TsqxZhjojUhadfE6lQZQW81R1Z6RZRHyEab+TpiiVHc4w1Mt0i6v/VoK5aGLuuxiIiRWCQIVIZW27G1RpZQenJ1LNioxC/PB0CYBZmjJFlVmwU3B8cAiQnW76gQgMMYMfVWESkKJxaIlIR4824/LSR8WacnJkL4O+RFWvrigSUhh/TyEoZMW1DsHBUZ2g15iFHq/Euvdm3C1VdiKluzRARKR9HZIhUorKbsYDSm/GgKK3tIytWllDHtA3BoCit2fRV98QZcGv3H4k3V/7Nvyo1Q5KrsYhIsRhkiFSiqjdj48hK+WkorY01Ie5uwt83dZXVwpRXo9VYRKRoDDJEKlGdm7HUyEqVzkx6/nng448t21USYIyqWzNERMrHIEOkEjUp4K3WdInKR2HKqvJqLCJSDRb7EqlETQp4q2T6dFXtC2MLY80QAIvPz5aaISJSLgYZIpVwyM1YEID33rNsV2mAKavS1Vhcek2kSjxriVxeVU+HllutbOr2+uvAm29atjvhXw+2/PtW23eCyBnx0Mi/MMhQRdS606tdb7ROVAtjD2r9ThA5Gx4aSVQJWzeXUyJjAe/DHe9Cj8gG1Qsxb7/tdLUwNaXm7wSRq2KQIZfk8ju9CgLw2muW7S4aYAB+J4jUikGGXFJ1T4dWvXnzOApjhct+J4hUjvvIkEtyyZ1eWQtTIZf8ThA5AY7IkEtyqZ1ely3jKIwNXOo7QeREOCJDLslldnrlKIzNXOY7QeRkOCJDLsnpd3pduZKjMFXk9N8JIifFIEMuy2l3ehUE4IknLNsZYCrltN8JIifGDfHI5TnNLq5r1gDDh1u2O/f/xWuF03wniFTM1vs3a2TI5VX7dGglYS2MXTnFd4LIRXBqiUjN1qxhLQwRuTSOyBCpFUdhiIg4IkOkOlu2SIcYg4EhhohcDkdkiNSEozBERGY4IkOkBjt3chSGiEgCR2SIlI6jMEREVnFEhkipUlM5CkNEVAmOyBApEUdhiIhswhEZIiX59VfpEKPXM8QQEUngiAyRUnAUhoioyjgiQyS3jAzpEHPnDkMMEVElOCJDJCeOwhAR1QhHZIjkkJkpHWJu32aIISKqAo7IEDkaR2GIiOyGIzJEjnLsmHSIuXVLNSFGbxCRmn0V6zPOIzX7KvQGdfSbiJwXR2SIHMEJRmGSM3Mxe0MWcnXFprYQjTdmxUYhpm2IjD0jIlfGERmi2pSdLR1iiotVF2Lil6ebhRgAyNMVI355OpIzc2XqGRG5OgYZotoiCEDz5pbtogh4eTm+P9WkN4iYvSELUrHL2DZ7QxanmYhIFgwyRPZ26pT0KMyff6pqFMYoLeeaxUhMWSKAXF0x0nKuOa5TRER/YY0MkT05QS1MeZcKrIeYsvacvIxLBcUICvBGt4j6cHez8lkQEdkRgwyRPZw9CzRpYtleWAj4+jq+P3YUFOBt03Ufb8s2/TOLgInIUTi1RFRTgiAdYkRR9SEGALpF1EeIxhtVGV9hETAROQqDDFF15eZKTyUVFJhNJal97xV3NwGzYqMAwOYwI/71wyJgIqptnFoiqg4ba2GcZe+VmLYhWDiqs8WfpTLGIuAekQ1qsXdE5MoYZIiq4tIlIDjYsl2nAwIDzZqMe6+UH48wTrssHNVZdWFmUJQWaTnXcKmgGMfzCvDJ9uxKn5eXb3vwISKqKk4tEdlKEKRDjChahBhn3XvF3U1Aj8gGeLjjXajv52nTc67dLKnlXhGRK2OQIarMlSvSU0nXrlldVu0Ke6/YGmRsvY6IqDo4tURUkWruC2Pr3iu2XqdEWo2PXa8jIqoOjsgQSbl+XTrEXL5s0+Z2tu69Yut1SmRcll2REE3p5nhERLWFQYaoPEEA6kvcfEURaNjQppeobO8VAeq/yRuXZVf0Z5wVG8UdfomoVjHIKIDa9xlxGjqd9CjMxYtVPmKgor1XjL87w03euCy7/MhMiMZbdauyiEidBFFU8SEwNsjPz4dGo4FOp0NguZUlSuAs+4yoXi2dkeQq/371BtG0LJtnLRGRPdh6/2aQkZG1fUaMf/3zv2gdoLAQ8Pe3bL9wAQixz2fPmzwRUdXZev/mqiWZVLbPiIDSfUYGRWl506stDjqp2rj3ChER2R9rZGTiCvuMKNaff0qHmAsX7B5iiIiodnFERiZK2mfEpaY+HDQKQ0REjsEgIxOl7DPiKsWoKCkBvCU+y7NngcaNHd8fIiKyC04tyUQJ+4wYi43LT3EZDzVMzsyttfd2KEGQDjGiyBBDRKRyDDIykXufEWc91NDMrVvSU0mnTnEqiYjISTDIyMi4mZi23GZiWgdsJub0xcaCAHh5WbaLItC0qeP7Q0REtYI1MjKLaRuCQVFahxfbKqnY2K7u3AHq1LFs/+MPICLC8f0hIqJaxSCjAHLsM6KUYmO74ookIiKXw6klF6WEYmO70eulQ8zx4wwxREROjkHGRcldbGw3ggB4SAwsiiLQooXj+0NERA7FIOPC5Cw2rjFrozBZWRyFISJyIayRcXFyFRvXCGthiIjoLwwypJ5DDQ0GwN3dsv2334B27RzfHyIikp2ip5beeOMNCIJg9tOqVSu5u0VyEATpECOKDDFERC5M8SMybdq0QUpKiul3D6nCTnJeogi4SeTt9HSgUyfH94eIiBRF8anAw8MDWq1W7m6QHFgLQ0RElVD01BIAnDhxAqGhoWjWrBlGjhyJM2fOVHh9SUkJ8vPzzX5IZURROsSkpTHEEBGRGUUHme7du2PZsmVITk7GwoULkZOTgz59+qCgoMDqcxITE6HRaEw/YWFhDuwx1ZggSE8liSJwzz2O7w8RESmaIIrq+U/cGzduoGnTpnj//ffx9NNPS15TUlKCkpIS0+/5+fkICwuDTqdDYGCgo7pKVWWtFuaXX4AePRzfHyIiklV+fj40Gk2l92/F18iUVbduXdx99904efKk1Wu8vLzgJXXqMSkXa2GIiKiaFD21VN7NmzeRnZ2NkBAF7zhLVSMVYnbsYIghIiKbKHpEZtq0aYiNjUXTpk1x4cIFzJo1C+7u7njiiSfk7hrVVJ06wJ07lu0MMEREVAWKDjLnzp3DE088gatXr6JRo0bo3bs39u7di0aNGsndNaoJqVGYlBRgwADH94WIiFRN0UFm5cqVcneB7CkwEJBaccZRGCIiqiZV1ciQigmCZYj56SeGGCIiqhFFj8iQE9BqgYsXLdsZYIiIyA44IkO1RxAsQ8zGjQwxRERkNxyRIfsLDwdOn7ZsZ4AhIiI744gM2ZcgWIaY1asZYoiIqFZwRIbso1Ur4Ngxy3YGGCIiqkUckaGaEwTLELNqFUMMERHVOo7IUPV16gRkZFi2M8AQEZGDcESGqkcQLEPM8uUMMURE5FAckaGq6dkTSE21bGeAISIiGXBEhmwnCJYh5osvGGKIiEg2HJGhyvXvD2zfbtnOAENERDLjiAxVTBAsQ8yiRQwxRESkCByRIWnPPgt89pllOwMMEREpCIMMWRIEy7bly4GRIx3fFyIiogowyKiU3iAiLecaLhUUIyjAG90i6sPdTSKAVMWkScCCBZbtHIUhIiKFYpBRoeTMXMzekIVcXbGpLUTjjVmxUYhpG1K9F5UahfniC2DMmGr2koiIqPax2FdlkjNzEb883SzEAECerhjxy9ORnJlbtRf86CPpECOKDDFERKR4DDIqojeImL0hC1ITPca22RuyoDfYOBUkCEBCgnnb4sWcSiIiItVgkFGRtJxrFiMxZYkAcnXFSMu5VvELffqp9VGYceNq1kk70htEpGZfxfqM80jNvmp7QCMiIpfBGhkVuVRgPcTYfJ1UgPnmG+DRR6vZq9pRK3VARETkdDgioyJBAd7Vv27jRuujMAoMMXatAyIiIqfFIKMi3SLqI0TjDWuLrAWUjlp0i6hf7gEBiI01b9u8WZG1MHavAyIiIqfGIKMi7m4CZsVGAYBFmDH+Pis26u/9ZDZtsj4KM3BgrfWzJuxWB0RERC6BQUZlYtqGYOGoztBqzKePtBpvLBzV+e/6EUEAhgwxf/KmTYochSnLLnVARETkMljsq0IxbUMwKEorvbPv5s3AAw9YPknhAcaoRnVARETkchhkVMrdTUCPyAbmjVLTSBs3Ag8+6JhO2YGxDihPVyxZJyOgdPTJog6IiIhcEqeWnMHWrdZrYVQUYoBq1AEREZFLY5BRKJs3gxMEYMAA87Z161QzlSTF5jogIiJyeZxaUiCbNoP77jvp/V9UHGDKqrAOiIiI6C+CKDrJnc+K/Px8aDQa6HQ6BAYGyt2dShk3gyv/L8V4+144qjNi2oVaPnH1amDYsNruHhERkUPYev/miIyCVLYZ3AMn9iKm3UMSDzp1FiUiIrKKQUZBKtoM7lSSRIB57z1g6tRa7hUREZFyMcgoiNQmb/2z92Ppd7MtL+YoDBEREYOMkpTf5E1qFObdvk+hzxfvo4ejOkVERKRgDDIKYtwMLvjIIaz7r+WUUcSMjdBqvDGVm8EREREBYJBRFHc3AamvWB7mOK/3SHzc6wkAjt8MTm8QuQSaiIgUi0FGKdLTgS5dLJrDZ2wEILGPjAPYtJ8NERGRjLiPjBIEBQGXL5s1GZZ8jn39h8o2EmLTfjYMM0REVEu4j4wanDoFRERYtosi3ADZCnor289GADB7QxYGRWk5zURERLLiWUtyad7cMsT88IMillVXtJ8NUBpmcnXFSMu55rhOERERSeCIjKOdPg2Eh1u2KyDAGEntZ1OT64iIiGoLR2QcqVUryxCzaZOiQgxguZ9NTa8jIiKqLRyRcYRz54CwMMt2hQUYI+N+Nnm6Ysk6GQGAVlNagExERCQnjsjUtg4dLEOMQmphrHF3EzArNgrA36uUjIy/O3o/GyIiIikMMrXl/HlAEIDffjNvF0VgyBB5+lQFMW1DsHBUZ2g15tNHWo03l14TEZFicGqpNnTpUrrBXVnr1wP/+Ic8/ammmLYhGBSl5c6+RESkWAwy9pSbC4SGWrYreBqpMu5uAnpENpC7G0RERJI4tWQv3btbhpi1a1UdYoiIiJSOIzI1dfEioNVatjPAEBER1TqOyNTEQw9Zhphvv2WIISIichCOyFTX88+XLqMuiwGGiIjIoTgiU12//PL3P69cyRBDREQkA47IVNeBA8AffwDNmsndEyIiIpfFEZmaYIghIiKSFYMMERERqRaDDBEREakWgwwRERGpFoMMERERqRaDDBEREakWgwwRERGpFoMMERERqRaDDBEREakWgwwRERGpFoMMERERqRaDDBEREakWgwwRERGpFk+/ria9QURazjVcKihGUIA3ukXUh7ubIHe3KqXWfhMREUlhkKmG5MxczN6QhVxdsaktROONWbFRiGkbImPPKqbWfhMREVnDqaUqSs7MRfzydLMwAAB5umLEL09HcmauTD2rmFr7TUREVBFVBJlPPvkE4eHh8Pb2Rvfu3ZGWliZLP/QGEbM3ZEGUeMzYNntDFvQGqSvko9Z+ExERVUbxQWbVqlWYMmUKZs2ahfT0dHTo0AHR0dG4dOmSw/uSlnPNYkSjLBFArq4YaTnXHNcpG6i130RERJVRfJB5//33MW7cOIwZMwZRUVFYtGgRfH198cUXXzi8L5cKrIeB6lznKGrtNxERUWUUHWRu3bqFAwcOYODAgaY2Nzc3DBw4EKmpqZLPKSkpQX5+vtmPvQQFeNv1OkdRa7+JiIgqo+ggc+XKFej1egQHB5u1BwcHIy8vT/I5iYmJ0Gg0pp+wsDC79adbRH2EaLxhbbGygNJVQN0i6tvtPe1Brf0mIiKqjKKDTHW8/PLL0Ol0pp+zZ8/a7bXd3QTMio2SLJo1hoRZsVGK25fF2G8AFmFGyf0mIiKqjKKDTMOGDeHu7o6LFy+atV+8eBFarVbyOV5eXggMDDT7sbe6vnUs2jS+dbBwVGfF7scS0zYEC0d1hlZjPn2k1Xgrut9EREQVUfSGeJ6enujSpQu2bNmCoUOHAgAMBgO2bNmCiRMnOrw/xr1YpEZkdEW3Hd6fqoppG4JBUVru7EtERE5D0UEGAKZMmYK4uDh07doV3bp1w4cffojCwkKMGTPGof2oaC8Wo9kbsjAoSqvoYODuJqBHZAO5u0FERGQXig8yjz/+OC5fvozXX38deXl56NixI5KTky0KgGtbVfZiYVAgIiJyDMUHGQCYOHGiLFNJZXEvFiIiIuVRdLGvknAvFiIiIuVhkLER92IhIiJSHgYZG3EvFiIiIuVhkKkC7sVCRESkLKoo9lUS7sVCRESkHAwy1cC9WIiIiJSBU0tERESkWgwyREREpFoMMkRERKRaDDJERESkWgwyREREpFoMMkRERKRaDDJERESkWgwyREREpFoMMkRERKRaTr+zryiKAID8/HyZe0JERES2Mt63jfdxa5w+yBQUFAAAwsLCZO4JERERVVVBQQE0Go3VxwWxsqijcgaDARcuXEBAQAAEwfaDHfPz8xEWFoazZ88iMDCwFntIZfFzlwc/d8fjZy4Pfu7yqM7nLooiCgoKEBoaCjc365UwTj8i4+bmhsaNG1f7+YGBgfyyy4Cfuzz4uTseP3N58HOXR1U/94pGYoxY7EtERESqxSBDREREqsUgY4WXlxdmzZoFLy8vubviUvi5y4Ofu+PxM5cHP3d51Obn7vTFvkREROS8OCJDREREqsUgQ0RERKrFIENERESqxSBDREREqsUgI+GTTz5BeHg4vL290b17d6SlpcndJaeWmJiIe+65BwEBAQgKCsLQoUNx7Ngxubvlct555x0IgoCEhAS5u+L0zp8/j1GjRqFBgwbw8fFBu3bt8Ouvv8rdLaem1+sxc+ZMREREwMfHB5GRkXjzzTcrPceHqmbnzp2IjY1FaGgoBEHAunXrzB4XRRGvv/46QkJC4OPjg4EDB+LEiRM1ek8GmXJWrVqFKVOmYNasWUhPT0eHDh0QHR2NS5cuyd01p7Vjxw5MmDABe/fuxebNm3H79m088MADKCwslLtrLmP//v347LPP0L59e7m74vSuX7+OXr16oU6dOti0aROysrIwb9481KtXT+6uObWkpCQsXLgQH3/8MY4cOYKkpCS8++67WLBggdxdcyqFhYXo0KEDPvnkE8nH3333XcyfPx+LFi3Cvn374Ofnh+joaBQXF1f/TUUy061bN3HChAmm3/V6vRgaGiomJibK2CvXcunSJRGAuGPHDrm74hIKCgrEFi1aiJs3bxb79esnvvDCC3J3yanNmDFD7N27t9zdcDkPPvigOHbsWLO2YcOGiSNHjpSpR84PgLh27VrT7waDQdRqteLcuXNNbTdu3BC9vLzE//3vf9V+H47IlHHr1i0cOHAAAwcONLW5ublh4MCBSE1NlbFnrkWn0wEA6tevL3NPXMOECRPw4IMPmn3vqfZ8//336Nq1Kx599FEEBQWhU6dOWLJkidzdcno9e/bEli1bcPz4cQDAoUOHsHv3bgwePFjmnrmOnJwc5OXlmf1do9Fo0L179xrdY53+0MiquHLlCvR6PYKDg83ag4ODcfToUZl65VoMBgMSEhLQq1cvtG3bVu7uOL2VK1ciPT0d+/fvl7srLuOPP/7AwoULMWXKFLzyyivYv38/Jk2aBE9PT8TFxcndPaf10ksvIT8/H61atYK7uzv0ej3efvttjBw5Uu6uuYy8vDwAkLzHGh+rDgYZUpQJEyYgMzMTu3fvlrsrTu/s2bN44YUXsHnzZnh7e8vdHZdhMBjQtWtXzJkzBwDQqVMnZGZmYtGiRQwyteibb77B119/jRUrVqBNmzbIyMhAQkICQkND+bmrHKeWymjYsCHc3d1x8eJFs/aLFy9Cq9XK1CvXMXHiRGzcuBHbtm1D48aN5e6O0ztw4AAuXbqEzp07w8PDAx4eHtixYwfmz58PDw8P6PV6ubvolEJCQhAVFWXW1rp1a5w5c0amHrmG6dOn46WXXsKIESPQrl07/Otf/8LkyZORmJgod9dchvE+au97LINMGZ6enujSpQu2bNliajMYDNiyZQt69OghY8+cmyiKmDhxItauXYutW7ciIiJC7i65hAEDBuD3339HRkaG6adr164YOXIkMjIy4O7uLncXnVKvXr0sthc4fvw4mjZtKlOPXENRURHc3Mxvee7u7jAYDDL1yPVERERAq9Wa3WPz8/Oxb9++Gt1jObVUzpQpUxAXF4euXbuiW7du+PDDD1FYWIgxY8bI3TWnNWHCBKxYsQLr169HQECAaa5Uo9HAx8dH5t45r4CAAIs6JD8/PzRo0ID1SbVo8uTJ6NmzJ+bMmYPHHnsMaWlpWLx4MRYvXix315xabGws3n77bTRp0gRt2rTBwYMH8f7772Ps2LFyd82p3Lx5EydPnjT9npOTg4yMDNSvXx9NmjRBQkIC3nrrLbRo0QIRERGYOXMmQkNDMXTo0Oq/aQ1WVjmtBQsWiE2aNBE9PT3Fbt26iXv37pW7S04NgOTP0qVL5e6ay+Hya8fYsGGD2LZtW9HLy0ts1aqVuHjxYrm75PTy8/PFF154QWzSpIno7e0tNmvWTHz11VfFkpISubvmVLZt2yb593lcXJwoiqVLsGfOnCkGBweLXl5e4oABA8Rjx47V6D0FUeS2hkRERKROrJEhIiIi1WKQISIiItVikCEiIiLVYpAhIiIi1WKQISIiItVikCEiIiLVYpAhIiIi1WKQISIiItVikCEiVdHr9ejZsyeGDRtm1q7T6RAWFoZXX31Vpp4RkRy4sy8Rqc7x48fRsWNHLFmyBCNHjgQAPPXUUzh06BD2798PT09PmXtIRI7CIENEqjR//ny88cYbOHz4MNLS0vDoo49i//796NChg9xdIyIHYpAhIlUSRRH3338/3N3d8fvvv+P555/Ha6+9Jne3iMjBGGSISLWOHj2K1q1bo127dkhPT4eHh4fcXSIiB2OxLxGp1hdffAFfX1/k5OTg3LlzcneHiGTAERkiUqVffvkF/fr1w88//4y33noLAJCSkgJBEGTuGRE5EkdkiEh1ioqKMHr0aMTHx6N///74z3/+g7S0NCxatEjurhGRg3FEhohU54UXXsCPP/6IQ4cOwdfXFwDw2WefYdq0afj9998RHh4ubweJyGEYZIhIVXbs2IEBAwZg+/bt6N27t9lj0dHRuHPnDqeYiFwIgwwRERGpFmtkiIiISLUYZIiIiEi1GGSIiIhItRhkiIiISLUYZIiIiEi1GGSIiIhItRhkiIiISLUYZIiIiEi1GGSIiIhItRhkiIiISLUYZIiIiEi1GGSIiIhItf4fr8hSWenbaJ4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(50, 1) * 10\n",
    "y = 2 * X + 1 + np.random.randn(50, 1) * 2  # True relationship: y = 2*X + 1\n",
    "\n",
    "# Fit a linear regression model\n",
    "model_with_bias = LinearRegression()\n",
    "model_with_bias.fit(X, y)\n",
    "\n",
    "# Plot the true relationship and the model's predictions\n",
    "plt.scatter(X, y, label='True Data')\n",
    "plt.plot(X, model_with_bias.predict(X), color='red', label='Model with Bias')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression with Bias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Variance:\n",
    "If a model which predicts well with training dataset and fails with independent unseen data (Testing dataset), then it is evident that model has a variance. Resulted Error from Test Data.\n",
    "* High Variance: When the test error is high.\n",
    "* Low Variance: When the test error is minimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Overfitting:\n",
    "Overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data. Intuitively, overfitting occurs when the model or the algorithm fits the data too well. Specifically, overfitting occurs if the model or algorithm shows low bias but high variance.\n",
    "\n",
    "Ways to Reduce High Variance:\n",
    "1. Reduce the input features or number of parameters as a model is overfitted.\n",
    "2. Do not use a complex model.\n",
    "3. Increase the training data.\n",
    "4. Increase the Regularization term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Underfitting:\n",
    "Specifically, underfitting occurs if the model or algorithm shows low variance but high bias. A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on testing data(low variance) but performs poorly on training data(high bias).\n",
    "\n",
    "Techniques to reduce underfitting: \n",
    "1. Increase model complexity.\n",
    "2. Increase the number of features, performing feature engineering.\n",
    "3. Remove noise from the data.\n",
    "4. Increase the number of epochs or increase the duration of training to get better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Different Combinations of Bias-Variance:***\n",
    "1. Low-Bias, Low-Variance:The combination of low bias and low variance shows an ideal machine learning model. However, it is not possible practically.\n",
    "2. Low-Bias, High-Variance: With low bias and high variance, model predictions are inconsistent and accurate on average. This case occurs when the model learns with a large number of parameters and hence leads to an overfitting\n",
    "3. High-Bias, Low-Variance: With High bias and low variance, predictions are consistent but inaccurate on average. This case occurs when a model does not learn well with the training dataset or uses few numbers of the parameter. It leads to underfitting problems in the model.\n",
    "4. High-Bias, High-Variance: With high bias and high variance, predictions are inconsistent and also inaccurate on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bias-Variance Trade-Off:***\n",
    "\n",
    "While building the machine learning model, it is really important to take care of bias and variance in order to avoid overfitting and underfitting in the model. If the model is very simple with fewer parameters, it may have low variance and high bias. Whereas, if the model has a large number of parameters, it will have high variance and low bias. So, it is required to make a balance between bias and variance errors, and this balance between the bias error and variance error is known as the Bias-Variance trade-off.\n",
    "\n",
    "key-points:\n",
    "1. If we decrease the variance, it will increase the bias.\n",
    "2. If we decrease the bias, it will increase the variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [8. Evaluation Matrix:](#h_cell)\n",
    "<a id='em_cell'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [9. Curse of dimensionality:](#h_cell)\n",
    "<a id='pca_cell'></a>\n",
    "The curse of dimensionality is a problem that arises when we are working with a lot of data having multiple features or we can say it as high dimensional data. The dimension of the data means the no. of features or columns in our dataset.\n",
    "<p align=\"center\"><img width=\"80%\" src=\"../images/curse-of-dimentionality.png\" /></p>\n",
    "\n",
    "1.  Suppose we have 4 data points in one dimension(only one feature in the data set). dimension space is equal to 4.\n",
    "2. Now if we add one more feature, then this will cause an increase in dimension space to $4\\times4 =16$.\n",
    "3. Again if we add one more feature to it, dimension space will increase to $4\\times 4 \\times 4 = 64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***Hughes Phenomenon:*** This phenomenon states that “with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as the number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.\n",
    "\n",
    "2. ***Effect of Curse of Dimensionality on Distance Functions:*** For any point A, let's assume distₘᵢₙ(A) is the minimum distance between A and its nearest neighbor and distₘₐₓ(A) is the maximum distance between A and the farthest neighbor.\n",
    "    * In One dimentional, 2-D or even 3-D data space $\\displaystyle\\frac{(dist_{\\max(A)}-dist_{\\min(A)})} {(dist_{\\min(A)})}\\gt 0$\n",
    "    * But as the dimention increase $\\displaystyle \\lim_{dim \\to\\infty}\\frac{(dist_{\\max(A)}-dist_{\\min(A)})} {(dist_{\\min(A)})}\\to 0$\n",
    "\n",
    "    * That is, for a d — dimensional space, given n-random points, the distₘᵢₙ(A) ≈ distₘₐₓ(A) meaning, any given pair of points are equidistant to each other.\n",
    "    \n",
    "Therefore, any machine learning algorithms which are based on the distance measure including KNN(k-Nearest Neighbor) tend to fail when the number of dimensions in the data is very high. Thus,dimensionality can be considered as a “curse” in such algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why should we look at dimensionality reduction?\n",
    "1. ***Dimentionality Reduction:*** Dimensionality reduction is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its natural dimension or in simple words, it means reducing the dimensions of our data set. Example: 1000-D->100-D\n",
    "2. Benefits:\n",
    "    * Speeds up algorithms.\n",
    "    * Reduces space used by data for them.\n",
    "    * Dimensionality reduction can improve how we display information in a tractable manner for human consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principle Component Analysis(PCA):\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique commonly used in statistics and machine learning to transform high-dimensional data into a lower-dimensional representation while preserving as much of the original data's variability as possible. It's particularly useful for visualizing data, removing noise, and improving the efficiency of machine learning algorithms.\n",
    "\n",
    "key-Points:\n",
    "1. The transform features are linearly independent.\n",
    "2. Dimentionality can be reduced by taking only the dimentions with the highest importance.\n",
    "3. Those newly found dimentions should minimize the projection error\n",
    "4. The projected points should have maximum spread, ex- maximum variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA Analysis:\n",
    "1. Say we have a 2D data set which we wish to reduce to 1D, to that to find a single line onto which to project this data.\n",
    "    * The distance between each point and the projected version should be small.\n",
    "    * PCA tries to find a lower dimensional surface so the sum of squares onto that surface is minimized.\n",
    "    * The blue lines are sometimes called the projection error\n",
    "    * PCA tries to minimize that error.\n",
    "    * do mean normalization and feature scaling on your data before PCA.\n",
    "    * For 2D-1D, we must find a vector u(1), which is of some dimensionality.\n",
    "        * u(1) can be positive or negative (-u(1)) which makes no difference.\n",
    "    * To reduce from nD to kD:\n",
    "        * Find k vectors (u(1), u(2), ... u(k)) onto which to project the data to minimize the projection error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA Alogorithm:\n",
    "1. Before applying PCA must do data preprocessing.\n",
    "    * Mean normalization\n",
    "        * Replace each $x_j^i \\text{ with } x_j - \\mu_j$,\n",
    "        * In other words, determine the mean of each feature set, and then for each feature subtract the mean from the value, so we re-scale the mean to be 0.\n",
    "    * Feature scaling (depending on data)\n",
    "        * If features have very different scales then scale so they all have a comparable range of values\n",
    "            * e.g. $x_j^i$ is set to $(x_j - \\mu_j) / s_j$ \n",
    "            * Where $s_j$ is some measure of the range, so could be \n",
    "            * Biggest - smallest\n",
    "        * Standard deviation (more commonly)\n",
    "2. Need to compute two things;\n",
    "    * Compute the u vectors for the new planes.\n",
    "    * Need to compute the z vectors, z vectors are the new, lower dimensionality feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "\n",
    "1. Variance: calculate the variance. $\\sigma(X)=\\displaystyle \\frac {1}{n}\\sum_{i=1}^{n}(X_i-\\bar X)^2$\n",
    "\n",
    "2. Covariance Matrix: $cov(X,Y)=\\displaystyle \\frac {1}{n}\\sum_{i=1}^{n}(X_i-\\bar X)(Y_i-\\bar Y)^T$ and $cov(X,X)=\\displaystyle \\frac {1}{n}\\sum_{i=1}^{n}(X_i-\\bar X)(x_i-\\bar X)^T$\n",
    "\n",
    "3. Calculate EigenVector and EigenValue for the covariance matrix: $Av=\\lambda v$\n",
    "    * [U,S,V] = svd(sigma)\n",
    "        * svd = singular value decomposition, More numerically stable than eig\n",
    "        * eig = also gives eigenvector\n",
    "    * U,S and V are matrices\n",
    "        * U matrix is also an [n x n] matrix\n",
    "        * Turns out the columns of U are the u vectors we want!\n",
    "        * So to reduce a system from n-dimensions to k-dimensions\n",
    "        * Just take the first k-vectors from U (first k columns)$U_{reduce}= U(:,1:k)$\n",
    "\n",
    "4. Next we need to find some way to change x (which is n dimensional) to z (which is k dimensional).\n",
    "    * (reduce the dimensionality)\n",
    "    * Take first k columns of the u matrix and stack in columns\n",
    "        * n x k matrix - call this $U_{reduce}$\n",
    "    * We calculate z as follows: $z =U_{reduce'} * x$\n",
    "        * $z = (U_{reduce})T * x$\n",
    "        * So [k x n] * [n x 1]\n",
    "        * Generates a matrix which is k * 1\n",
    "4. Sort the EigenVectors according to their EigenValues in decreasing order.\n",
    "5. Choose first k EigenVectors and that will be new K dimentions.\n",
    "6.Transform the n dimentional data points into k dimentions(=projections with dot product)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing the number of Principle Components.\n",
    "1. Try PCA with k = 1; number of principle components\n",
    "\n",
    "2. Compute $U_reduce, Z_1, Z_2 ...  \\text { and } x^{(1)}_{approx} ...$\n",
    "\n",
    "3. Check $\\displaystyle \\frac{\\frac{1}{m}\\sum_{i=1}^{m}\\|x^i-x^{i}_{approx}\\|^2} {\\frac{1}{m}\\sum_{i=1}^{m}\\|x^i\\|^2}\\leq 0.01$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 Cross Validation:](#h_cell)\n",
    "<a id='cv_cell'></a>\n",
    "\n",
    "Cross-validation is a technique used in machine learning and statistics to evaluate the performance of a predictive model. The purpose of cross-validation is to assess how well a model can generalize to new data that was not used in the training phase.\n",
    "\n",
    "The basic idea behind cross-validation is to split the available data into two sets: a training set and a validation set. The model is trained on the training set, and its performance is evaluated on the validation set. This process is repeated multiple times, with different subsets of the data used as the training and validation sets each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods of Cross-Validation:\n",
    "1. Hold Out Cross Validation or Train-Test split\n",
    "2. Leave-P-out cross-validation\n",
    "3. Leave one out cross-validation\n",
    "4. K-fold cross-validation\n",
    "5. Stratified k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hold Out Cross Validation or Train-Test split: In this technique of cross-validation, the whole dataset is randomly partitioned into a training set and validation set. Using a rule of thumb nearly 70% of the whole dataset is used as a training set and the remaining 30% is used as the validation set.\n",
    "    * Advantage:\n",
    "        * We usually use the hold-out method on large datasets as it requires training the model only once.\n",
    "    * Disadvantage:\n",
    "        * Not suitable for an imbalance data set.\n",
    "        * It is not suitable for small data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Leave-P-out cross-validation: LeavePOut cross-validation is an exhaustive cross-validation technique, in which p-samples are used as the validation set and remaining n-p samples are used as the training set. All possible combinations of p are tested on the model so as to get the maximum accuracy.\n",
    "    * Advantage: \n",
    "        * All the data samples get used as both training and validation samples.\n",
    "        * Get the best accuracy from the model.\n",
    "    * Disadvantage:\n",
    "        * Require more computational time.\n",
    "        * It is not suitable for imbalance datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Leave one out cross-validation: LOOCV is an extreme version of k-fold cross-validation that has the maximum computational cost. It requires one model to be created and evaluated for each example in the training dataset. Suppose we have 100 samples in the dataset. Then in each iteration 1 value will be used as a validation set and the remaining 99 samples as the training set. Thus the process is repeated till every sample of the dataset is used as a validation point.\n",
    "\t* Key Point:\n",
    "        * Don’t use it for large datasets\n",
    "        * Use only when the dataset is small or we need more accurate prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. K-fold cross-validation: In this technique of K-Fold cross-validation, the whole dataset is partitioned into K parts of equal size. Each partition is called a “Fold“.So as we have K parts we call them K-Folds. One Fold is used as a validation set and the remaining K-1 folds are used as the training set.\n",
    "    * The technique is repeated K times until each fold is used as a validation set and the remaining folds as the training set.\n",
    "    * The final accuracy of the model is computed by taking the mean accuracy of the k-models validation data.\n",
    "    \n",
    "    <p align=\"center\"><img width=\"80%\" src=\"../images/k-fold.png\" /></p>\n",
    "\n",
    "\n",
    "    * Pros:\n",
    "        * The whole dataset is used as both a training set and validation set.\n",
    "        * This will aid in resolving the computing power issue.\n",
    "        * Models may be unaffected by the presence of an outlier in the data.\n",
    "        * It assists us in overcoming the issue of unpredictability.\n",
    "\t* Cons:\n",
    "        * Not to be used for imbalanced datasets: As discussed in the case of HoldOut cross-validation, in the case of K-Fold validation too it may happen that all samples of training set will have no sample form class “1” and only of class “0”.And the validation set will have a sample of class “1”.\n",
    "        * Not suitable for Time Series data: For Time Series data the order of the samples matter. But in K-Fold Cross-Validation, samples are selected in random order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stratified k-fold cross-validation: Stratified K-Fold is an enhanced version of K-Fold cross-validation which is     mainly used for imbalanced datasets. Just like K-fold, the whole dataset is divided into K-folds of equal size. But in this technique, each fold will have the same ratio of instances of the target variable as in the whole datasets.\n",
    "    * Pros: Works perfectly well for Imbalanced Data: Each fold in stratified cross-validation will have a representation of data of all classes in the same ratio as in the whole dataset.\n",
    "    * Cons: not working for a time series dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-Z Artificial Intellegence Udemy:\n",
    "#### 5#Plan and Policy:\n",
    "Plan: when agent exactly know the enviroment like what to do next is called plan. But agent leran what is the best reward by experiencing and expolition called policy. \n",
    "### 6# Living Penalty:\n",
    "A reward  is continuously given to agent throughout the game rather than end time.  Giving agent always negative reward is called `Living penalty`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8# Temporal Difference\n",
    "$$\\mathcal {q_{*}(s,a)=R^{a}_{s}+\\gamma\\sum_{s'\\in S}P^{a}_{ss'}\\max_{a'} q_{*}(s',a')}$$\n",
    "Write that equation in `deterministic` way:\n",
    "$$\\mathcal {q_{*}(s,a)=R^{a}_{s}+\\gamma\\max_{a'} q_{*}(s',a')}$$\n",
    "\n",
    "TD: The diffenece between current action-value and previous action-value though we calculating same thing in differnt time.\n",
    "$$TD(a,s)= R^{a}_a +\\gamma\\max_{a'} q_{*}(s',a')- q_{*}(s,a)$$\n",
    "Update q-value:\n",
    "$$TD(a,s)= R^{a}_a +\\gamma\\max_{a'} q_{*}(s',a')- q^{*}_{t-1}(s,a)$$\n",
    "\n",
    "$$\\mathcal{q_t(s,a)=q_{t-1}(s,a)+\\alpha TD_{t}(a,s)}$$\n",
    "or\n",
    "$$\\mathcal{q_t(s,a)=q_{t-1}(s,a)+\\alpha (R^{a}_a +\\gamma\\max_{a'} q_{*}(s',a')- q^{*}_{t-1}(s,a))}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep-Q-Learning\n",
    "\n",
    "\n",
    "##### Experinece Reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

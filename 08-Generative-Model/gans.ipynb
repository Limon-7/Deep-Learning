{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversial Network:\n",
    "\n",
    "<p align=\"center\"><img width=\"70%\" src=\"../images/gan_diagram.svg\" /></p>\n",
    "\n",
    "A generative adversarial network (GAN) has two parts:\n",
    "1. ***`Generator:`*** The generator learns to generate plausible data from a latent variable(Probabilitisc).\n",
    "2. ***`Discriminator:`*** The discriminator learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n",
    "\n",
    "Both the generator and the discriminator are neural networks. The generator output is connected directly to the discriminator input. Through backpropagation, the discriminator's classification provides a signal that the generator uses to update its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Training the Generator:\n",
    "The generator is not directly connected to the loss that we're trying to affect. The generator feeds into the discriminator net, and the discriminator produces the output we're trying to affect. The generator loss penalizes the generator for producing a sample that the discriminator network classifies as fake.\n",
    "\n",
    "So we train the generator with the following procedure:\n",
    "1. Sample random noise.\n",
    "2. Produce generator output from sampled random noise.\n",
    "3. Get discriminator \"Real\" or \"Fake\" classification for generator output.\n",
    "4. Calculate loss from discriminator classification.\n",
    "5. Backpropagate through both the discriminator and generator to obtain gradients.\n",
    "6. Use gradients to change only the generator weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Training the Discriminator:\n",
    "The discriminator connects to two loss functions. During discriminator training, the discriminator ignores the generator loss and just uses the discriminator loss.\n",
    "\n",
    "During discriminator training:\n",
    "\n",
    "1. The discriminator classifies both real data and fake data from the generator.\n",
    "2. The discriminator loss penalizes the discriminator for misclassifying a real instance as fake or a fake instance as real.\n",
    "3. The discriminator updates its weights through backpropagation from the discriminator loss through the discriminator network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN Training:\n",
    "Because a GAN contains two separately trained networks, GANs must juggle two different kinds of training (generator and discriminator). GAN uses alternate training(the generator and discriminator are alternately updated to improve their performance.)\n",
    "\n",
    "1. The discriminator trains for one or more epochs.\n",
    "2. The generator trains for one or more epochs.\n",
    "3. Repeat steps 1 and 2 to continue to train the generator and discriminator networks.\n",
    "\n",
    "The generator keeps constant during the discriminator training phase. As discriminator training tries to figure out how to distinguish real data from fake, it has to learn how to recognize the generator's flaws.\n",
    "\n",
    "The discriminator keeps constant during the generator training phase. Otherwise the generator would be trying to hit a moving target and might never converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMax Loss Function:\n",
    "The generator tries to minimize the following function while the discriminator tries to maximize it-\n",
    "$$min_{\\theta_{g}} \\; max_{\\theta_{d}}[E_x[log(D(x))] + E_z[log(1 - D(G(z)))]]$$\n",
    "\n",
    "- Discriminator outputs likelihood in (0,1) of real image\n",
    "- Discriminator $(θ_d)$ wants to **maximize objective** such that D(x) is close to 1 (real) and D(G(z)) is close to 0 (fake)\n",
    "- Generator $(θ_g)$ wants to **minimize objective** such that D(G(z)) is close to 1 (discriminator is fooled into thinking generated G(z) is real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

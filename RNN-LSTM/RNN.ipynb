{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Recurrent neural networks\n",
    "### 2. RNN\n",
    "### 3. language modeling\n",
    "### 4. Image captioning\n",
    "### 5. soft attention\n",
    "### 6. LSTM\n",
    "### 7. GRU\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Recurrent neural networks:\n",
    "Recurrent neural networks, also known as RNNs, are a class of neural networks that allow previous outputs to be used as inputs while having hidden states.\n",
    "\n",
    "1. Why We need RRN?\n",
    "\n",
    "Vanilla Neural Networks \"Feed neural networks\", input of fixed size goes through some hidden units and then go to output. We call it a one to one network. So the traditional Neural Network only ***depend on imput data and can not work with sequential data so this kind of network can not memorize previous data.***\n",
    "`Recurrent neural networks allow us to operate a sequences or variable length of input , output or both at a same time.`\n",
    "\n",
    "2. ***The pros and cons of a typical RNN architecture are summed up in the table below:***\n",
    "\n",
    "Advantages|drawbacks|\n",
    ":---|---:|\n",
    "| Possibility of processing input of any length| Computation being slow.|\n",
    "| Model size not increasing with size of input| Difficulty of being getting information long time ago|\n",
    "| Computation takes into account historical information| can not consider any future input for the current state|\n",
    "| Weights are shared across time|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application and Types of RNN:\n",
    "1. ***Image Captioning:*** Image captioning is the process of `generating a textual description` or caption that accurately describes the content of an image. It combines computer vision techniques for understanding the visual content of an image. Generally use **`one-to-many`** model.\n",
    "\n",
    "2. ***Sentiment Classification:*** Sentiment classification is the task of automatically determining the sentiment expressed in a given piece of text. The goal is to classify the text into different sentiment categories, such as positive, negative or neutral. Another example, taking input as a sequence of video frames and produce a label what action was happening in that video. Generally use ***`many-to-one`*** model.\n",
    "\n",
    "3. ***Machine Translation:*** takes a sequence of words of a sentence in English, and then this RNN is asked to produce a sequence of words of a sentence in French. Another example, taking input as a sequence of video frames and produce a label for each label what action was happening in that frames. Generally use ***`many-to-many`*** model.\n",
    "\n",
    "![types-of-rnn](../images/RNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76159416]\n",
      " [0.29131261]\n",
      " [0.09966799]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.76159416]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "h=[[1],[.3],[.1]]+[[0],[0],[1],[0]]\n",
    "print(np.tanh(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
